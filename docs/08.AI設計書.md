# AI漫画生成サービス AI設計書

**文書管理情報**
- 文書ID: AI-DOC-001
- 作成日: 2025-01-20
- 版数: 3.0
- 承認者: 根岸祐樹
- 関連文書: SYS-DOC-001（システム設計書）、TEST-DOC-001（テスト設計書）
- 更新履歴:
  - v1.0: 基本設計完成
  - v2.0: HITL統合・品質制御強化
  - v3.0: Phase2-7詳細実装仕様統合 (Phase2-7_Implementation_Strategy.md統合)
- **更新内容**: HITL（Human-in-the-loop）システム統合対応

## 目次

- [1. AI設計概要](#1-ai設計概要)
  - [1.1 AI設計方針](#11-ai設計方針)
  - [1.2 統合モジュールアーキテクチャ](#12-統合モジュールアーキテクチャ)
- [2. 7フェーズHITLシステム設計](#2-7フェーズhitlシステム設計)
  - [2.1 HITLモジュール統合設計](#21-hitlモジュール統合設計)
  - [2.2 フィードバック処理パイプライン](#22-フィードバック処理パイプライン)
  - [2.3 フェーズ仕様](#23-フェーズ仕様)
- [3. プロンプトエンジニアリング設計](#3-プロンプトエンジニアリング設計)
  - [3.1 動的プロンプトシステム](#31-動的プロンプトシステム)
  - [3.2 構造化テンプレート管理](#32-構造化テンプレート管理)
  - [3.3 プロンプト最適化戦略](#33-プロンプト最適化戦略)
- [4. 品質制御システム](#4-品質制御システム)
  - [4.1 基本品質評価](#41-基本品質評価)
  - [4.2 品質ゲート実装](#42-品質ゲート実装)
  - [4.3 リトライ機構](#43-リトライ機構)
- [5. AI学習・改善システム](#5-ai学習改善システム)
  - [5.1 フィードバック収集](#51-フィードバック収集)
  - [5.2 基本改善プロセス](#52-基本改善プロセス)
  - [5.3 統計分析](#53-統計分析)
- [6. 外部AI API統合設計](#6-外部ai-api統合設計)
  - [6.1 Google Gemini Pro統合](#61-google-gemini-pro統合)
  - [6.2 Google Imagen 4統合](#62-google-imagen-4統合)
  - [6.3 APIレート制限管理](#63-apiレート制限管理)
- [7. AI処理パフォーマンス設計](#7-ai処理パフォーマンス設計)
  - [7.1 処理時間最適化](#71-処理時間最適化)
  - [7.2 並列処理設計](#72-並列処理設計)
  - [7.3 リソース効率化](#73-リソース効率化)
- [8. AI倫理・安全性設計](#8-ai倫理安全性設計)
  - [8.1 コンテンツ安全性](#81-コンテンツ安全性)
  - [8.2 バイアス軽減](#82-バイアス軽減)
  - [8.3 透明性確保](#83-透明性確保)

---

## 1. AI設計概要

### 1.1 AI設計方針

#### 基本原則
| 原則 | 内容 | 実装アプローチ |
|------|------|---------------|
| HITL統合 | 7フェーズユーザー参加型処理 | インタラクティブフィードバックシステム |
| 品質協調 | ユーザーとAIの協調による品質向上 | リアルタイムフィードバック統合 |
| 効率的相互作用 | 30秒タイムアウト付きスムーズなやり取り | EventTarget+自然言語処理 |
| 継続学習 | フィードバックからの自動学習 | フィードバック分析・改善サイクル |

#### AI設計思想
```yaml
AI Design Philosophy:
  Processing Model: Human-in-the-loop協調型
    - 各フェーズでユーザーフィードバック統合
    - AI提案→ユーザー確認・修正→反映のサイクル
    - 自然言語フィードバック処理による学習
    
  Quality Assurance: 協調品質管理
    - AI品質評価とユーザー主観評価の統合
    - フィードバック統合による継続的改善
    - 品質ゲートによる段階的品質保証
    
  User Experience: 参加型創作支援
    - リアルタイムプレビューによる即座の確認
    - 直感的フィードバック入力インターフェース
    - 応答性を重視したスムーズな進行
    
  Performance Requirements:
    - フェーズ間遷移: 最適化された応答時間
    - ユーザーフィードバック処理: リアルタイム対応
    - 品質評価サイクル: 効率的な評価プロセス
```

### 1.2 統合モジュールアーキテクチャ

#### 統合AIサービス構成
```mermaid
graph TB
    subgraph "AI創作支援システム アーキテクチャ"
        subgraph "7フェーズ創作パイプライン"
            P1[Phase1: コンセプト・世界観分析]
            P2[Phase2: キャラクター設計]
            P3[Phase3: ストーリー構造設計]
            P4[Phase4: ネーム構成生成]
            P5[Phase5: ビジュアル生成]
            P6[Phase6: 対話配置最適化]
            P7[Phase7: 品質統合・調整]
        end
        
        subgraph "品質保証システム"
            QS[品質戦略管理]
            QG[品質ゲート制御]
            QA[品質分析評価]
        end
        
        subgraph "プロンプト戦略管理"
            PS[プロンプト戦略]
            TS[テンプレート戦略]
            OS[最適化戦略]
        end
        
        subgraph "データフロー管理"
            DF[データフロー制御]
            CS[状態管理戦略]
            ES[エラー回復戦略]
        end
    end
    
    subgraph "外部AI連携層"
        GA[生成AI統合層]
        IA[画像AI統合層]
    end
    
    P1 --> P2 --> P3 --> P4 --> P5 --> P6 --> P7
    
    QS --> QG --> QA
    QS -.-> P1 & P2 & P3 & P4 & P5 & P6 & P7
    
    subgraph "HITL統合戦略"
        FS[フィードバック戦略]
        IS[インタラクション戦略]
        AS[適応学習戦略]
    end
    
    FS --> IS --> AS
    FS -.-> P1 & P2 & P3 & P4 & P5 & P6 & P7
    
    DF --> CS --> ES
    
    P1 & P2 & P3 & P4 & P7 --> GA
    P5 --> IA
```

---

## 2. 7フェーズAIモジュール設計

### 2.1 モジュール統合設計

#### 統合AIサービスクラス
```python
from abc import ABC, abstractmethod
import asyncio
import json
from datetime import datetime
from typing import Dict, Any, List

class IntegratedAIService:
    """
    統合AI処理サービス
    """
    
    def __init__(self, redis_client):
        self.redis = redis_client
        self.modules = self._initialize_modules()
        self.quality_manager = QualityManager()
        self.prompt_manager = PromptManager()
        self.data_pipeline = DataPipeline()
        
    def _initialize_modules(self) -> Dict[str, 'BaseAIModule']:
        return {
            'phase1_concept': ConceptAnalysisModule(),        # Phase1: コンセプト・世界観分析
            'phase2_character': CharacterDesignModule(),      # Phase2: キャラクター設定
            'phase3_plot': PlotStructureModule(),            # Phase3: プロット・ストーリー構成
            'phase4_name': NameGenerationModule(),           # Phase4: ネーム生成（Phase1情報を活用）
            'phase5_scene': SceneImageGenerationModule(),    # Phase5: シーン画像生成
            'phase6_dialog': DialogPlacementModule(),        # Phase6: セリフ配置
            'phase7_final': FinalIntegrationModule()         # Phase7: 最終統合・品質調整
        }
    
    async def process_request(self, request_id: str, input_data: dict) -> dict:
        """
        統合処理実行（インメモリパイプライン）
        """
        context = ProcessingContext(
            request_id=request_id,
            data=input_data,
            metadata={}
        )
        
        # モジュールを順次実行
        for module_name, module in self.modules.items():
            try:
                start_time = datetime.now()
                
                # モジュール実行
                context = await module.process_with_quality_gate(
                    context, 
                    self.quality_manager,
                    self.prompt_manager
                )
                
                processing_time = (datetime.now() - start_time).total_seconds()
                context.metadata[f'{module_name}_duration'] = processing_time
                
                # 非同期チェックポイント保存
                asyncio.create_task(
                    self.save_checkpoint(request_id, module_name, context)
                )
                
            except Exception as e:
                await self.handle_module_error(request_id, module_name, e, context)
                raise
        
        return context.data
    
class BaseAIModule(ABC):
    """
    AIモジュール基底クラス
    """
    
    def __init__(self, module_name: str):
        self.module_name = module_name
        self.quality_threshold = 0.70
        self.max_retries = 3
        
    @abstractmethod
    async def process(self, context: 'ProcessingContext') -> 'ProcessingContext':
        """
        モジュール固有の処理ロジック
        """
        pass
    
    @abstractmethod
    async def evaluate_quality(self, context: 'ProcessingContext') -> float:
        """
        出力品質評価
        """
        pass
    
    async def process_with_quality_gate(
        self, 
        context: 'ProcessingContext',
        quality_manager: 'QualityManager',
        prompt_manager: 'PromptManager'
    ) -> 'ProcessingContext':
        """
        品質ゲート付きモジュール実行
        """
        retry_count = 0
        best_result = None
        best_score = 0.0
        
        while retry_count < self.max_retries:
            try:
                # プロンプト最適化
                optimized_context = await prompt_manager.optimize_for_module(
                    self.module_name, context
                )
                
                # モジュール処理実行
                result_context = await self.process(optimized_context)
                
                # 品質評価
                quality_score = await self.evaluate_quality(input_data, output)
                
                # 結果記録
                result = {
                    'agent_id': self.agent_id,
                    'request_id': request_id,
                    'output': output,
                    'quality_score': quality_score,
                    'processing_time': processing_time,
                    'retry_count': retry_count,
                    'timestamp': datetime.now().isoformat()
                }
                
                # 品質ゲート判定
                if quality_score >= self.quality_threshold:
                    await self.log_success(result)
                    await self.save_result_to_redis(request_id, result)
                    return result
                
                # 品質不足 - 最良結果を記録
                if quality_score > best_score:
                    best_result = result
                    best_score = quality_score
                
                retry_count += 1
                await self.log_retry(request_id, retry_count, quality_score)
                
            except Exception as e:
                retry_count += 1
                await self.log_error(request_id, retry_count, str(e))
        
        # 最終失敗処理
        if best_result and best_score > 0.60:  # 60%以上なら許容
            await self.log_degraded_success(best_result)
            return best_result
        else:
            raise QualityGateFailure(f"Agent {self.agent_id} failed quality gate")
    
    async def save_result_to_redis(self, request_id: str, result: dict):
        """
        処理結果をRedisに保存
        """
        key = f"request:{request_id}:{self.agent_id}:result"
        await self.redis.setex(key, 86400, json.dumps(result))  # 24時間TTL
```

#### Phase 1: コンセプト・世界観分析エージェント
```python
class ConceptAnalysisAgent(BaseAIAgent):
    def __init__(self, redis_client, pubsub_client):
        super().__init__("phase1-concept-analysis", redis_client, pubsub_client)
        self.gemini_client = self.initialize_gemini_client()
        self.prompt_manager = DynamicPromptManager("plot_generation")
        
    async def process(self, input_data: dict) -> dict:
        """
        コンセプト・世界観分析処理（コンセプト・テーマ・ジャンル・ターゲット読者層・世界観決定）
        """
        text = input_data['text']
        user_preferences = input_data.get('preferences', {})
        
        # 包括的コンセプト分析用動的プロンプト
        prompt = await self.prompt_manager.get_optimized_prompt({
            'text_length': len(text),
            'style': style,
            'genre': self.detect_genre(text)
        })
        
        # Gemini Pro API 呼び出し
        response = await self.gemini_client.generate_content(
            prompt.format(text=text, style=style)
        )
        
        # プロット結果パース
        plot_result = self.parse_plot_result(response.text)
        
        return {
            'concept': analysis_result['concept'],  # 作品の主要コンセプト
            'theme': analysis_result['theme'],  # メインテーマ
            'genre': analysis_result['genre'],  # ジャンル（少年、少女、青年等）
            'target_audience': analysis_result['target_audience'],  # ターゲット読者層
            'world_setting': analysis_result['world_setting'],  # 世界観・設定
            'tone': analysis_result['tone'],  # 作品のトーン（明るい、シリアス等）
            'estimated_length': analysis_result['estimated_length']  # 想定ページ数
        }
    
    async def evaluate_quality(self, input_data: dict, output_data: dict) -> float:
        """
        テキスト解析品質評価
        """
        scores = []
        
        # キャラクター抽出品質
        character_score = self.evaluate_character_extraction(
            input_data['text'], output_data['characters']
        )
        scores.append(character_score * 0.4)
        
        # テーマ理解品質
        theme_score = self.evaluate_theme_understanding(
            input_data['text'], output_data['themes']
        )
        scores.append(theme_score * 0.3)
        
        # 構造理解品質
        structure_score = self.evaluate_structure_understanding(
            input_data['text'], output_data['chapters']
        )
        scores.append(structure_score * 0.3)
        
        return sum(scores)
```

#### Phase 2: キャラクター設計戦略
**設計アプローチ**
- **統合的キャラクター設計**: コンセプト情報を活用した一貫性のあるキャラクター構築
- **多面的設計戦略**: 外観・性格・背景・関係性の包括的設計
- **ビジュアル参考生成**: 初期ビジュアルアイデア提供による創作支援

**品質保証戦略**
```yaml
Character Design Quality:
  Consistency Check: 一貫性評価
    - Phase1のコンセプト・世界観との整合性
    - キャラクター間の関係性の論理性
    - 設定の内部矛盾検出
    
  Design Depth: 設計深度評価
    - キャラクター背景の詳細度
    - 成長・変化の可能性設計
    - 読者共感度の予測評価
    
  Visual Coherence: ビジュアル統合性
    - 世界観とのビジュアル適合性
    - キャラクター識別性の確保
    - 表現技法の一貫性
```
        
**期待成果物**
- 主要キャラクターの詳細プロファイル
- キャラクター間関係性マトリックス
- 参考ビジュアルアイデア（1-2枚のコンセプトアート）
- 後続フェーズへの設計指針
    
    async def generate_character_visuals(self, character_details: dict, genre: str, world_setting: str) -> list:
        """
        主要キャラクターの簡易ビジュアル生成（1-2枚）
        """
        main_characters = self.select_main_characters(character_details, max_count=2)
        visual_tasks = []
        
        for character in main_characters:
            # キャラクター用プロンプト生成
            prompt = await self.create_character_visual_prompt(character, genre, world_setting)
            
            # Imagen 4による画像生成
            visual_task = self.imagen_client.generate_images(
                prompt=prompt,
                num_images=1,
                safety_filter_level=3,
                aspect_ratio="1:1"  # キャラクター参考用
            )
            visual_tasks.append(visual_task)
        
        # 並列実行
        visual_results = await asyncio.gather(*visual_tasks)
        
        return [
            {
                'character_name': char['name'],
                'visual_url': result['image_url'],
                'description': char['appearance']
            }
            for char, result in zip(main_characters, visual_results)
        ]
        
        return {
            'panel_layouts': name_result['panel_layouts'],  # コマ割り
            'rough_sketches': name_result['rough_sketches'],  # ラフスケッチ
            'dialog_placements': name_result['dialog_placements'],  # セリフ配置
            'page_compositions': name_result['page_compositions'],  # ページ構成
            'scene_transitions': name_result['scene_transitions'],  # シーン転換
            'reading_flow': name_result['reading_flow']  # 読み流し設計
        }
    
    async def generate_comprehensive_name(self, plot: dict, characters: list) -> dict:
        """
        包括的なネーム生成（プロ漫画家の最重要工程）
        """
        # ページごとのコマ割り設計
        panel_layouts = await self.design_panel_layouts_per_page(plot)
        
        # ラフスケッチ生成（簡単な絵でストーリーを表現）
        rough_sketches = await self.create_rough_sketches(plot, panel_layouts)
        
        # セリフとナレーション配置
        dialog_placements = await self.place_dialogs_and_narrations(plot, panel_layouts)
        
        # ページ構成と見開き設計
        page_compositions = await self.design_page_compositions(panel_layouts)
        
        return {
            'panel_layouts': panel_layouts,
            'rough_sketches': rough_sketches,
            'dialog_placements': dialog_placements,
            'page_compositions': page_compositions,
            'scene_transitions': await self.analyze_scene_transitions(panel_layouts),
            'reading_flow': await self.optimize_reading_flow(panel_layouts)
        }
```

#### Phase 3: ストーリー構造設計戦略

**ナラティブ構築アプローチ**
- **階層的構造設計**: テーマ・キャラクターを統合した総合的プロット構築
- **感情曲線最適化**: 読者の感情体験を考慮したストーリー展開
- **ペーシング管理**: リズムと緊張感のバランス調整

**品質保証戦略**
```yaml
Story Structure Quality:
  Narrative Coherence: ナラティブ一貫性
    - ストーリーラインの論理性評価
    - キャラクター動機の一貫性確認
    - 世界観との整合性検証
    
  Emotional Impact: 感情的インパクト
    - クライマックスの効果測定
    - 感情変化の自然さ評価
    - 読者共感度の予測
    
  Pacing Balance: ペーシングバランス
    - シーン長の最適分配
    - 緊張と弛緩のリズム調整
    - 展開速度の適切性
```

**期待成果物**
- 詳細プロット構造（起承転結）
- シーン分解と進行設計
- 感情曲線マッピング
- ペーシング最適化指針

#### Phase 4: ネーム構成生成戦略（最重要工程）

**ビジュアルコミュニケーション戦略**
- **コマ割り最適化**: ストーリーテリングと読みやすさのバランス
- **演出設計戦略**: 感情表現と視覚的インパクトの最大化
- **読み流し設計**: 自然な視線誘導とページターン最適化

**技術的アプローチ**
```yaml
Storyboard Design Approach:
  Panel Composition: コマ構成戦略
    - シーン重要度に応じたコマサイズ配分
    - ページ全体のバランスとリズム調整
    - クライマックスシーンの大コマ配置
    
  Visual Direction: 演出指示戦略
    - カメラアングルの慈意的選択
    - キャラクターポジションの物語性考慮
    - 背景と効果線の気分造成
    
  Reading Flow: 読み流し最適化
    - コマ間の連続性とリズム調整
    - ページメクリと大コマの効果的配置
    - シーン転換のスムーズな演出
```

**期待成果物**
- コマ割り設計（ページごとの最適配置）
- シーン生成詳細指示（背景・キャラクター・効果）
- カメラアングル指定（俲角・アオリ・バストショット等）
- 読み流し最適化指針
    
    async def generate_comprehensive_name(self, plot: dict, characters: list) -> dict:
        """
        包括的なネーム生成
        """
        # ページごとの最適なコマ数決定
        panel_layouts = await self.design_optimal_panel_counts(plot)
        
        # 重要シーンの大ゴマ配置
        key_panels = await self.place_key_scene_panels(plot, panel_layouts)
        
        # 視線誘導を考慮したレイアウト
        optimized_layouts = await self.optimize_reading_flow(panel_layouts)
        
        # シーン生成詳細指示生成
        scene_instructions = await self.generate_scene_instructions(plot, characters)
        
        # カメラアングル設定（俯瞰、アオリ、正面、バストショット等）
        camera_angles = await self.determine_camera_angles(scene_instructions)
        
**パフォーマンス最適化戦略**
- **ビジュアル効率性**: コマ構成の最適化と読み流しへの影響最小化
- **シーン演出効率**: キャラクター配置と背景要素のバランス最適化
- **演出効果設計**: 効果線と視覚効果の最大限活用

#### Phase 5: ビジュアル生成戦略（高度並列処理アーキテクチャ）

**パフォーマンス設計原則**
- **並列処理最適化**: シーン生成の高速化とリソース効率最大化
- **キャッシュ戦略**: 似たシーンの再利用による生成時間短縮
- **品質効率バランス**: 高速性と高品質の両立

**アーキテクチャ戦略**
```yaml
Visual Generation Architecture:
  Cache Strategy: キャッシュ最適化戦略
    - シーン類似度解析と再利用ロジック
    - インテリジェントキャッシュ管理
    - 動的キャッシュ無効化と更新
    
  Parallel Processing: 並列処理最適化
    - バッチサイズのAPI制限適応型調整
    - 非同期タスク管理とリソース割り当て
    - エラー耐性とリトライ機構
    
  Quality Assurance: 品質保証統合
    - リアルタイム品質評価と一貫性チェック
    - スタイル統一性とキャラクターアイデンティティ保持
    - 進捗追跡とユーザーフィードバック統合
```

**品質保証戦略**

| 品質評価軸 | 評価基準 | 重み付け |
|-----------|---------|----------|
| キャラクター精度 | Phase2設計との一致度 | 25% |
| スタイル一貫性 | 作品全体での視覚的統一性 | 20% |
| 構図品質 | コマ割りとの適合性 | 20% |
| 技術品質 | 解像度・色彩・細部品質 | 15% |
| 物語明確性 | シーン情報の伝達効果 | 10% |
| 芸術的魅力 | 美的評価と感情表現 | 10% |

**期待成果物**
- シーン別高品質画像セット
- シーン-画像マッピング
- 品質分析レポートと一貫性評価
- パフォーマンス効率性指標
        
        # 1. シーン類似度解析・キャッシュ検索
        cache_results = await self.cache_manager.check_scene_similarities(scenes, style)
        
        # 2. 生成が必要なシーンを特定
        scenes_to_generate = self.filter_uncached_scenes(scenes, cache_results)
        
        # 3. 並列バッチ処理
        generated_images = []
        total_scenes = len(scenes)
        completed_count = len(cache_results)  # キャッシュヒット分
        
        # バッチサイズは並列度とAPI制限を考慮
        batch_size = min(self.max_parallel_workers, len(scenes_to_generate))
        batches = self.create_batches(scenes_to_generate, batch_size)
        
        for batch_idx, batch in enumerate(batches):
            # 並列処理でバッチを処理
            batch_results = await self.process_batch_parallel(batch, characters, style)
            generated_images.extend(batch_results)
            
            # 進捗更新
            completed_count += len(batch_results)
            await self.progress_tracker.update_progress(
                request_id, 6, completed_count, total_scenes
            )
        
        # 4. 品質分析と一貫性評価
        quality_analysis = await self._analyze_generation_quality(generated_images)
        consistency_report = await self._generate_consistency_report(
            generated_images, character_designs
        )
        
        # 5. シーン-画像マッピング作成
        scene_image_mapping = await self._create_scene_image_mapping(
            generated_images, name_layout
        )
        
        # 6. 並列効率スコア計算
        parallel_efficiency_score = self._calculate_parallel_efficiency_score(
            generation_tasks, generated_images
        )
        
        result = {
            "generated_images": generated_images,
            "scene_image_mapping": scene_image_mapping,
            "quality_analysis": quality_analysis,
            "consistency_report": consistency_report,
            "generation_stats": self.generation_stats.copy(),
            "parallel_efficiency_score": parallel_efficiency_score,
            "cache_utilization": self._calculate_cache_utilization()
        }
        
        # 5. スタイル一貫性評価
        style_consistency = await self.calculate_style_consistency(final_images)
        
        return {
            'images': final_images,
            'total_images': len(final_images),
            'cache_hit_rate': len(cache_results) / total_scenes,
            'parallel_efficiency': await self.calculate_parallel_efficiency(),
            'style_consistency_score': style_consistency
        }
    
    async def process_batch_parallel(self, batch: List[Scene], characters: List, style: str) -> List[dict]:
        """
        バッチ内の画像を並列生成
        """
        tasks = []
        for scene in batch:
            task = self.generate_single_image(scene, characters, style)
            tasks.append(task)
        
        # 並列実行（例外も適切にハンドリング）
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # エラーの場合はフォールバック画像を生成
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                fallback_image = await self.create_fallback_image(batch[i], result)
                processed_results.append(fallback_image)
            else:
                processed_results.append(result)
        
        return processed_results
    
    async def generate_single_image(self, scene: dict, characters: List, style: str) -> dict:
        """
        単一シーンの画像生成
        """
        try:
            # 最適化されたプロンプト生成
            image_prompt = await self.prompt_manager.get_optimized_prompt({
                'scene_type': scene['type'],
                'characters_in_scene': scene['characters'],
                'emotion': scene['emotion'],
                'setting': scene['setting'],
                'style': style,
                'characters_reference': characters
            })
            
            # Imagen 4 API 呼び出し
            image_response = await self.imagen_client.generate_images(
                prompt=image_prompt,
                number_of_images=1,
                aspect_ratio='16:9',
                safety_filter_level='block_some'
            )
            
            generated_image = {
                'scene_id': scene['id'],
                'image_url': image_response.images[0].gcs_uri,
                'prompt_used': image_prompt,
                'generation_time': image_response.generation_time,
                'timestamp': datetime.now().isoformat()
            }
            
            # キャッシュに保存（非同期）
            asyncio.create_task(
                self.cache_manager.store_scene_image(scene, generated_image, style)
            )
            
            return generated_image
            
        except Exception as e:
            # エラーログ記録
            await self.log_generation_error(scene['id'], str(e))
            raise
    
    async def create_fallback_image(self, scene: dict, error: Exception) -> dict:
        """
        エラー時のフォールバック画像生成
        """
        # 簡素化されたプロンプトで再試行
        simplified_prompt = f"Simple {scene['type']} scene, {scene['setting']}"
        
        try:
            fallback_response = await self.imagen_client.generate_images(
                prompt=simplified_prompt,
                number_of_images=1,
                aspect_ratio='16:9',
                safety_filter_level='block_most'
            )
            
            return {
                'scene_id': scene['id'],
                'image_url': fallback_response.images[0].gcs_uri,
                'prompt_used': simplified_prompt,
                'generation_time': fallback_response.generation_time,
                'is_fallback': True,
                'original_error': str(error)
            }
            
        except:
            # 最終フォールバック：プレースホルダー画像
            return {
                'scene_id': scene['id'],
                'image_url': await self.generate_placeholder_image(scene),
                'prompt_used': 'placeholder',
                'generation_time': 0.1,
                'is_fallback': True,
                'is_placeholder': True,
                'original_error': str(error)
            }
    
    async def evaluate_quality(self, input_data: dict, output_data: dict) -> float:
        """
        画像生成品質評価
        """
        images = output_data['images']
        quality_scores = []
        
        for image in images:
            # 技術的品質評価
            tech_score = await self.evaluate_image_technical_quality(image['image_url'])
            
            # シーン一致度評価
            scene_score = await self.evaluate_scene_matching(
                input_data['scenes'], image
            )
            
            # スタイル一貫性評価
            style_score = output_data['style_consistency_score']
            
            image_quality = (tech_score * 0.4) + (scene_score * 0.4) + (style_score * 0.2)
            quality_scores.append(image_quality)
        
        return sum(quality_scores) / len(quality_scores) if quality_scores else 0.0
```

#### Phase 6: 対話配置最適化戦略

**テキストレイアウト最適化アプローチ**
- **読みやすさ最優先**: 吹き出しとセリフの直感的配置
- **視覚的バランス**: 画像とテキストの調和した統合
- **感情表現最大化**: オノマトペとナレーションの効果的配置

**設計戦略**
```yaml
Text Layout Design Strategy:
  Speech Bubble Optimization: 吹き出し最適化
    - コマ内スペースとの効率的バランス
    - 読み順序と視線誘導の最適化
    - キャラクターとの関係性明確化
    
  Typography Strategy: タイポグラフィ戦略
    - シーンの気分とフォントスタイル連動
    - キャラクターの性格とテキスト表現統合
    - 可読性と芸術性のバランス調整
    
  Sound Effect Integration: 効果音統合
    - オノマトペの視覚的インパクト最大化
    - シーンの動的感と音響効果の調和
    - ナレーションの物語進行支援機能
```

**期待成果物**
- 最適化された吹き出し配置
- シーンに合わせたセリフテキスト
- 効果的オノマトペ配置
- ナレーションとタイポグラフィ指定
    
    async def place_text_elements(self, images: dict, layout: dict, plot: dict) -> dict:
        """
        テキスト要素の最適配置
        """
        # 吹き出し位置の最適化
        speech_bubbles = await self.optimize_speech_bubble_positions(images, layout)
        
        # セリフの配置と調整
        dialog_texts = await self.place_dialogs(plot, speech_bubbles)
        
        # 効果音の配置
        sound_effects = await self.place_sound_effects(images, layout)
        
        # ナレーションの配置
        narration = await self.place_narration(plot, images)
        
        # テキストスタイルの設定
        text_styles = await self.determine_text_styles(dialog_texts, sound_effects)
        

#### Phase 7: 品質統合・調整戦略

**統合品質管理アプローチ**
- **全体統合最適化**: 全フェーズ成果のシームレスな統合
- **品質保証フレームワーク**: 統一性、完成度、表現力の総合評価
- **出力最適化**: 多様な形式と品質での最終成果物提供

**最終品質管理戦略**
```yaml
Final Quality Management:
  Integration Quality: 統合品質管理
    - フェーズ間一貫性の総合評価
    - シームレスな読み体験の確保
    - ビジュアルとテキストの調和性検証
    
  Output Optimization: 出力最適化
    - 多プラットフォーム対応形式
    - 高品質出力とファイルサイズの最適バランス
    - メタデータとトレーサビリティ情報
    
  Quality Assurance: 品質保証プロセス
    - 客観的指標と主観的評価の統合
    - ユーザーフィードバックの最終反映
    - 品質レポートと改善提案
```

**期待成果物**
- 統合された漫画作品（完成版）
- 総合品質スコアと評価レポート
- 多形式出力（PDF、WebP等）
- 作品メタデータと履歴情報
    
    async def integrate_all_elements(self, images: dict, text: dict) -> dict:
        """
        全要素の統合処理
        """
        # 画像とテキストの統合
        integrated_pages = []
        for page_id, page_images in images.items():
            page_text = text.get(page_id, {})
            integrated_page = await self.integrate_page(page_images, page_text)
            integrated_pages.append(integrated_page)
        
        # ページ順序の最適化
        ordered_pages = await self.optimize_page_order(integrated_pages)
        
        # 最終的な調整
        final_manga = await self.apply_final_adjustments(ordered_pages)
        
        return final_manga
```

### 2.3 HITL統合戦略

#### フィードバック統合アーキテクチャ
**フィードバック処理戦略**

```yaml
HITL Feedback Strategy:
  Natural Language Processing: 自然言語処理戦略
    - ユーザーフィードバックの意図解析
    - コンテキストを考慮したフィードバック分類
    - 各フェーズに適応した修正指示生成
    
  Real-time Integration: リアルタイム統合
    - WebSocketを活用した即座フィードバック反映
    - タイムアウト機構と適応型進行制御
    - 進捗状況の可視化とユーザー通知
    
  Quality Improvement: 品質改善サイクル
    - フィードバック履歴の分析と学習
    - AIモデルの継続的改善と適応
    - ユーザー嗜好の学習とカスタマイズ
```
    
**タイムアウト管理戦略**

| タイムアウト管理要素 | 戦略アプローチ | 期待効果 |
|-----------------|----------|--------|
| 待機時間最適化 | フェーズに応じた適切なタイムアウト設定 | ユーザー体験向上 |
| 適応型進行 | タイムアウト時のスムーズな継続機構 | 作品完成率向上 |
| リアルタイム通知 | WebSocketでの即座ステータス通知 | ユーザーエンゲージメント向上 |
| 挙動記録 | フィードバックパターンの学習と最適化 | AIシステムの継続改善 |
    
**データ継承戦略**
- **シームレスデータフロー**: フェーズ間の情報伝達と整合性保持
- **状態管理最適化**: Redisを活用した効率的なデータキャッシュ
- **エラー耐性設計**: データ異常時の回復機構とフォールバック戦略
    
    async def get_cumulative_context(self, request_id: str, current_phase: int) -> dict:
        """
        累積コンテキスト取得（必要に応じて）
        """
        context = {}
        
        # Phase 1-3: ストーリー基盤情報
        if current_phase >= 2:
            phase1_concept_data = await self.get_phase_data(request_id, 1)
            context['phase1_concept'] = phase1_concept_data
            
        if current_phase >= 3:
            phase2_character_data = await self.get_phase_data(request_id, 2)
            context['phase2_character'] = phase2_character_data
            
        # Phase 4以降: キャラクター・設定情報
        if current_phase >= 5:
            context['characters'] = await self.get_phase_data(request_id, 4)
            
        return context
```

### 2.3 フェーズ仕様

#### HITLフェーズ個別仕様
```yaml
HITL Phase Specifications:
  Phase1_ConceptAnalysis:
    AI_Input: {text: str, style: str, pages: int}
    AI_Output: {theme: str, genre: str, world_setting: str, target_audience: str, tone: str, keywords: list}
    User_Preview: "テーマ、ジャンル、世界観、対象読者層のプレビュー"
    Feedback_Options: ["テーマ修正", "ジャンル変更", "世界観調整", "雰囲気変更"]
    AI_API: Gemini Pro
    Processing_Time: "12s + 最大30分フィードバック待機"
    Quality_Metrics: [concept_clarity, user_satisfaction, feedback_integration]
    
  Phase2_CharacterDesign:
    AI_Input: {phase1_concept: dict, user_feedback_history: list}
    AI_Output: {characters: list, relationships: dict, visual_designs: list, reference_images: list}
    User_Preview: "キャラクター設定、関係性、ビジュアルデザインのプレビュー"
    Feedback_Options: ["キャラ追加/削除", "性格変更", "ビジュアル調整", "関係性修正"]
    AI_API: Gemini Pro + Imagen 4
    Processing_Time: "18s + 最大30分フィードバック待機"
    Quality_Metrics: [character_consistency, visual_quality, user_approval]
    
  Phase3_PlotStructure:
    AI_Input: {phase1_concept: dict, phase2_character: dict, user_feedback: list}
    AI_Output: {three_act_structure: dict, emotional_arc: list, page_allocation: dict}
    User_Preview: "3幕構成、起承転結、感情曲線のプレビュー"
    Feedback_Options: ["プロット変更", "ペーシング調整", "クライマックス修正"]
    AI_API: Gemini Pro
    Processing_Time: "15s + 最大30分フィードバック待機"
    Quality_Metrics: [plot_coherence, story_flow, user_approval]
    
**パフォーマンス目標と品質指標**

| フェーズ | 応答性目標 | 品質指標 | ユーザーエンゲージメント |
|-------|----------|--------|----------------|
| Phase 4 | 最適化されたレスポンス | レイアウト品質・演出効果 | インタラクティブコマ割り設計 |
| Phase 5 | 並列処理最適化 | 画像品質・スタイル一貫性 | ビジュアルプレビュー体験 |
| Phase 6 | 美黿なテキスト配置 | 可読性・バランス | 細かなカスタマイズ対応 |
| Phase 7 | 高速統合処理 | 全体一貫性・製品品質 | 最終品質確認 |

**システムレスポンス戦略**
- **応答性最適化**: 各フェーズでの効率的処理時間とユーザー体験のバランス
- **アダプティブタイムアウト**: ユーザーのペースに合わせた柔軟なフィードバック待機
- **リアルタイムエンゲージメント**: 積極的ユーザー参加と即座フィードバック反映
- **シームレスデータフロー**: フェーズ間の情報継承と一貫性保持

## 3. 最適化アーキテクチャ戦略

### 3.1 並列処理最適化戦略

**フェーズ独立性設計原則**
```yaml
Parallel Processing Strategy:
  Phase Independence: フェーズ独立性最適化
    - Phase2-3の並列実行可能性分析
    - 依存関係の明確化と独立操作の特定
    - 結果統合ロジックの効率化
    
  Resource Optimization: リソース最適化
    - 非同期タスク管理とリソース割り当て
    - キャッシュ戦略とメモリ効率化
    - エラーハンドリングとリトライ機構
    
  Data Flow Optimization: データフロー最適化
    - フェーズ間データ継承の効率化
    - 一貫性チェックサムと整合性検証
    - 最適化されたデータ結合とキャッシュ管理
```

### 3.2 品質効率バランス戦略

**パフォーマンスと品質の最適バランス**
- **適応的品質制御**: ユーザーニーズに応じた動的品質調整
- **リアルタイム最適化**: 処理速度と品質の動的バランス調整
- **スケーラブル設計**: ロードに応じた柔軟なリソース配分

**総合パフォーマンス戦略**
- **効率的AI処理**: 最適化された応答性とユーザー体験の調和
- **ユーザーエンゲージメント**: 積極的参加とリアルタイムフィードバック統合
- **シームレスデータフロー**: フェーズ間の情報伝達と整合性保持システム

##### Phase 4 ネーム生成 詳細設計

###### コマ割りアルゴリズム
```python
def _determine_panel_count(self, pacing: str, genre: str) -> int:
    base_counts = {
        "fast": [2, 3, 4],      # アクション重視
        "medium": [3, 4, 5],    # バランス型
        "slow": [1, 2, 3]       # 感情重視
    }
    
    genre_modifiers = {
        "action": 0,            # 大きなパネル優先
        "romance": 1,           # 細かい感情表現
        "mystery": 1,           # 詳細な描写
        "slice_of_life": 1      # 日常の細やかさ
    }
    
    base_range = base_counts.get(pacing, base_counts["medium"])
    modifier = genre_modifiers.get(genre, 0)
    
    return random.choice(base_range) + modifier
```

###### 構図決定ロジック
```python
def _select_camera_angle(self, scene, panel_num, total_panels):
    # 導入パネル: wide_shot で状況説明
    if panel_num == 1 and total_panels > 1:
        return "wide_shot"
    
    # 最終パネル: close_up でリアクション
    if panel_num == total_panels and total_panels > 1:
        return "close_up"
        
    # シーン目的に応じた選択
    if "conflict" in scene.get("purpose", ""):
        return "medium_shot"
    elif "climax" in scene.get("purpose", ""):
        return "close_up"
    else:
        return "full_shot"
```

###### カメラアングル選択マトリックス
| シーン目的 | 推奨アングル | 理由 |
|------------|-------------|------|
| introduction | wide_shot | 状況・環境の説明 |
| conflict | medium_shot | キャラクター間の対立 |
| climax | extreme_close_up | 感情の最高潮 |
| resolution | full_shot | 全体的な解決感 |
| dialogue | close_up | キャラクター表情重視 |
| action | dynamic_angle | 躍動感の表現 |

###### ページレイアウト最適化
```python
def _calculate_visual_weight_distribution(self, panels):
    weights = []
    for panel in panels:
        size_weight = {"splash": 4, "large": 3, "medium": 2, "small": 1}[panel.size]
        angle_weight = {"extreme_close_up": 1.5, "close_up": 1.3, "medium_shot": 1.0, 
                       "full_shot": 0.8, "wide_shot": 0.6}[panel.camera_angle]
        weights.append(size_weight * angle_weight)
    
    max_weight = max(weights)
    total_weight = sum(weights)
    
    if max_weight / total_weight > 0.6:
        return "dominated"  # 1つのパネルが支配的
    elif max_weight / total_weight < 0.35:
        return "balanced"   # バランス良好
    else:
        return "weighted"   # 適度な重み付け
```

##### Phase 5 並列処理実装

###### シーンバッチング戦略
```python
async def _execute_parallel_generation(self, generation_tasks, session_id):
    # 5並列セマフォ制御
    async def generate_single_image(task):
        async with self.semaphore:  # max_concurrent_generations = 5
            return await self._generate_single_image(task, session_id)
    
    # 全タスクを同時開始、セマフォで制御
    results = await asyncio.gather(
        *[generate_single_image(task) for task in generation_tasks],
        return_exceptions=True
    )
    
    return self._process_parallel_results(results)
```

###### 優先度ベーススケジューリング
```python
def _calculate_panel_priority(self, panel_spec, all_panels):
    priority = 5  # ベース優先度
    
    # 早いパネルほど高優先度
    if panel_spec.page_number == 1:
        priority += 2
    
    # クライマックスパネルは高優先度
    if panel_spec.emotional_tone in ["climax", "tension"]:
        priority += 2
        
    # パネルサイズによる調整
    if panel_spec.size in ["splash", "large"]:
        priority += 1
    
    return min(10, max(1, priority))
```

###### 失敗時のリトライとフォールバック
```python
async def _generate_single_image(self, task, session_id):
    for attempt in range(task.max_retries + 1):
        try:
            # キャッシュ確認
            cache_key = self._generate_cache_key(task)
            if cache_key in self.image_cache:
                return self.image_cache[cache_key]
            
            # 画像生成実行
            result = await self._actual_image_generation(task)
            
            if result.get("success"):
                # キャッシュに保存
                self.image_cache[cache_key] = result
                return result
            else:
                if attempt < task.max_retries:
                    await asyncio.sleep(2 ** attempt)  # 指数バックオフ
                    continue
                    
        except Exception as e:
            if attempt < task.max_retries:
                await asyncio.sleep(2 ** attempt)
                continue
            else:
                # 最終フォールバック
                return await self._generate_fallback_image(task)
    
    return await self._generate_fallback_image(task)
```

###### キャッシュヒット最適化
```python
def _generate_cache_key(self, task):
    # プロンプトとスタイルパラメータのハッシュ
    cache_data = {
        "prompt": task.prompt,
        "negative_prompt": task.negative_prompt,
        "style": task.style_parameters,
        "dimensions": task.dimensions
    }
    cache_string = json.dumps(cache_data, sort_keys=True)
    return hashlib.md5(cache_string.encode()).hexdigest()
```

##### 品質制御メカニズム

###### フェーズ品質スコアリング
```python
class QualityMetric:
    def __init__(self, name, score, weight, details, recommendations):
        self.name = name
        self.score = score  # 0.0-1.0
        self.weight = weight  # 重み係数
        self.details = details
        self.recommendations = recommendations

quality_categories = {
    "visual_consistency": {"weight": 0.25},    # キャラクター・スタイル一貫性
    "narrative_coherence": {"weight": 0.20},   # 物語の整合性  
    "technical_quality": {"weight": 0.15},     # 技術的品質
    "readability": {"weight": 0.15},           # 読みやすさ
    "pacing_flow": {"weight": 0.10},           # ペーシング・フロー
    "character_development": {"weight": 0.10}, # キャラクター描写
    "artistic_appeal": {"weight": 0.05}        # 芸術的魅力
}
```

###### フィードバックループ設計
```python
async def apply_feedback(self, original_result, feedback):
    """ユーザーフィードバックの適用"""
    adjusted_result = original_result.copy()
    
    if feedback.get("type") == "regeneration":
        # 特定パネルの再生成
        panel_id = feedback.get("panel_id")
        new_result = await self._regenerate_panel(panel_id, feedback.get("modifications"))
        adjusted_result["generated_images"][panel_id] = new_result
        
    elif feedback.get("type") == "adjustment":
        # パラメータ調整
        adjustments = feedback.get("adjustments", {})
        adjusted_result.update(adjustments)
    
    adjusted_result["feedback_applied"] = feedback
    adjusted_result["feedback_timestamp"] = datetime.utcnow().isoformat()
    
    return adjusted_result
```

##### エラーハンドリング戦略

###### 段階的フォールバック
```python
class ErrorSeverity(Enum):
    LOW = "low"           # 警告レベル、処理継続
    MEDIUM = "medium"     # 一部機能制限で継続
    HIGH = "high"         # フェーズ失敗、リトライ
    CRITICAL = "critical" # パイプライン停止

async def handle_phase_error(self, error, phase_num):
    severity = self._assess_error_severity(error, phase_num)
    
    if severity == ErrorSeverity.LOW:
        self.log_warning(f"Phase {phase_num}: {error}")
        return "continue"
        
    elif severity == ErrorSeverity.MEDIUM:
        # 品質を下げて継続
        fallback_result = await self._generate_fallback_result(phase_num)
        return fallback_result
        
    elif severity == ErrorSeverity.HIGH:
        # リトライ実行
        return await self._retry_phase(phase_num)
        
    else:  # CRITICAL
        # パイプライン停止
        await self._emergency_shutdown(error)
        raise CriticalPipelineError(error)
```

##### パフォーマンス最適化

###### 並列効率スコア計算
```python
def _calculate_parallel_efficiency_score(self, generation_tasks, generation_results):
    # 理論的順次実行時間
    avg_single_time = self._calculate_average_generation_time(generation_results)
    theoretical_sequential_time = len(generation_tasks) * avg_single_time
    
    # 実際の並列実行時間
    actual_parallel_time = max(r.generation_time_ms for r in generation_results)
    
    # 効率スコア計算
    efficiency_score = 1.0 - (actual_parallel_time / theoretical_sequential_time)
    
    # 並列度による調整
    concurrency_benefit = min(1.0, self.max_concurrent_generations / len(generation_tasks))
    adjusted_score = efficiency_score * (0.5 + 0.5 * concurrency_benefit)
    
    return round(max(0.0, min(1.0, adjusted_score)), 3)
```

---

## 3. プロンプトエンジニアリング設計

### 3.1 動的プロンプトシステム

#### 動的プロンプト選択エンジン
```python
class DynamicPromptManager:
    def __init__(self, agent_type: str):
        self.agent_type = agent_type
        self.template_store = PromptTemplateStore()
        self.optimizer = PromptOptimizer()
        self.performance_tracker = PromptPerformanceTracker()
        
    async def get_optimized_prompt(self, context: dict) -> str:
        """
        コンテキストに最適化されたプロンプト取得
        """
        # 1. コンテキスト分析
        context_features = self.extract_context_features(context)
        
        # 2. 最適テンプレート選択
        template_id = await self.select_best_template(context_features)
        
        # 3. テンプレート取得・パラメータ注入
        template = await self.template_store.get_template(template_id)
        prompt = await self.inject_parameters(template, context)
        
        # 4. 動的最適化適用
        optimized_prompt = await self.optimizer.optimize_prompt(prompt, context_features)
        
        # 5. 使用記録
        await self.performance_tracker.log_prompt_usage(template_id, context_features)
        
        return optimized_prompt
    
    def extract_context_features(self, context: dict) -> dict:
        """
        コンテキスト特徴抽出
        """
        features = {}
        
        if self.agent_type == "phase1_concept":
            features = {
                'text_length_category': self.categorize_text_length(context.get('text_length', 0)),
                'style': context.get('style', '少年漫画'),
                'complexity': context.get('complexity', 'medium')
            }
        elif self.agent_type == "image_generation":
            features = {
                'scene_type': context.get('scene_type', 'dialogue'),
                'character_count': len(context.get('characters_in_scene', [])),
                'emotion_intensity': context.get('emotion', 'neutral'),
                'setting_complexity': context.get('setting', 'simple'),
                'style': context.get('style', '少年漫画')
            }
        
        return features
    
    async def select_best_template(self, context_features: dict) -> str:
        """
        最適テンプレート選択
        """
        # パフォーマンス履歴取得
        template_performance = await self.performance_tracker.get_template_performance(
            self.agent_type, context_features
        )
        
        # 成功率が最も高いテンプレートを選択
        best_template = max(
            template_performance.items(),
            key=lambda x: x[1]['success_rate']
        )
        
        return best_template[0]
```

### 3.2 構造化テンプレート管理

#### 階層的プロンプトテンプレート
```python
class PromptTemplateStore:
    def __init__(self):
        self.templates = self.load_template_hierarchy()
        
    def load_template_hierarchy(self) -> dict:
        """
        階層的テンプレート構造読み込み
        """
        return {
            "phase1_concept": {
                "base": {
                    "id": "phase1_concept_base",
                    "template": """
あなたは漫画制作の専門家です。以下のテキストを分析し、漫画制作に必要な要素を抽出してください。

【分析対象テキスト】
{text}

【出力形式】
JSON形式で以下の項目を出力してください：
- characters: 主要キャラクター名のリスト（最大10名）
- themes: 物語のテーマ（最大5つ）
- emotions: 物語全体の感情（最大3つ）
- chapters: 章・場面の区切り
- complexity_score: 複雑度スコア（0.0-1.0）

【注意事項】
- 客観的な分析に徹してください
- 既存作品との類似は避けてください
- {style}スタイルに適した解釈をしてください
""",
                    "parameters": ["text", "style"]
                },
                "short_text": {
                    "id": "phase1_concept_short",
                    "inherits": "phase1_concept_base",
                    "modifications": {
                        "additional_instruction": "短いテキストのため、詳細な補完分析を行ってください。"
                    }
                },
                "long_text": {
                    "id": "phase1_concept_long",
                    "inherits": "phase1_concept_base", 
                    "modifications": {
                        "additional_instruction": "長編テキストのため、重要な要素のみを抽出してください。"
                    }
                },
                "complex_text": {
                    "id": "phase1_concept_complex",
                    "inherits": "phase1_concept_base",
                    "modifications": {
                        "additional_instruction": "複雑な構造のため、段階的に分析してください。"
                    }
                }
            },
            "phase5_scene": {
                "base": {
                    "id": "phase5_scene_base",
                    "template": """
{style}スタイルの漫画の1シーンを生成してください。

【シーン情報】
- 場面: {setting}
- キャラクター: {characters}
- 感情: {emotion}
- アクション: {action}

【スタイル指定】
- 漫画スタイル: {style}
- 構図: {composition}
- カラーパレット: {color_palette}

【品質要件】
- 高解像度（1024x1024以上）
- キャラクターの一貫性維持
- 読みやすい構図
- 適切な感情表現

【禁止事項】
- 既存作品キャラクターの模倣
- 不適切な表現
- 著作権侵害的な要素
""",
                    "parameters": ["style", "setting", "characters", "emotion", "action", "composition", "color_palette"]
                },
                "action_scene": {
                    "id": "phase5_scene_action",
                    "inherits": "phase5_scene_base",
                    "modifications": {
                        "additional_instruction": "動的でエネルギッシュな構図を重視してください。"
                    }
                },
                "dialogue_scene": {
                    "id": "phase5_scene_dialogue", 
                    "inherits": "phase5_scene_base",
                    "modifications": {
                        "additional_instruction": "キャラクターの表情と感情表現を重視してください。"
                    }
                }
            }
        }
    
    async def get_template(self, template_id: str) -> dict:
        """
        テンプレート取得（継承処理含む）
        """
        # テンプレート階層を辿って最終テンプレート生成
        agent_type, template_name = template_id.split('_', 1)
        template_config = self.templates[agent_type][template_name]
        
        # 基底テンプレートから継承
        if 'inherits' in template_config:
            base_template = await self.get_template(f"{agent_type}_{template_config['inherits']}")
            final_template = self.merge_templates(base_template, template_config)
        else:
            final_template = template_config
        
        return final_template
    
    def merge_templates(self, base: dict, override: dict) -> dict:
        """
        テンプレート継承・マージ処理
        """
        merged = base.copy()
        
        # 基本テンプレートに追加指示を統合
        if 'modifications' in override:
            modifications = override['modifications']
            if 'additional_instruction' in modifications:
                merged['template'] += f"\n\n【追加指示】\n{modifications['additional_instruction']}"
        
        return merged
```

### 3.3 プロンプト最適化戦略

#### A/Bテストによる最適化
```python
class PromptOptimizer:
    def __init__(self):
        self.experiment_manager = ABTestManager()
        self.performance_analyzer = PromptPerformanceAnalyzer()
        
    async def optimize_prompt(self, base_prompt: str, context_features: dict) -> str:
        """
        プロンプト最適化
        """
        # 現在実行中のA/Bテスト確認
        active_experiments = await self.experiment_manager.get_active_experiments(
            self.agent_type, context_features
        )
        
        if active_experiments:
            # A/Bテスト参加
            selected_variant = await self.experiment_manager.select_variant(active_experiments[0])
            optimized_prompt = self.apply_variant_modifications(base_prompt, selected_variant)
        else:
            # 標準プロンプト使用
            optimized_prompt = base_prompt
        
        return optimized_prompt
    
    async def create_prompt_experiment(self, template_id: str, variants: list) -> str:
        """
        プロンプトA/Bテスト作成
        """
        experiment = {
            'id': f"prompt_exp_{datetime.now().strftime('%Y%m%d_%H%M')}",
            'template_id': template_id,
            'variants': variants,
            'success_metric': 'quality_score',
            'traffic_split': {'control': 50, 'variant_a': 25, 'variant_b': 25},
            'duration_days': 7,
            'min_samples': 100
        }
        
        await self.experiment_manager.create_experiment(experiment)
        return experiment['id']

class PromptPerformanceTracker:
    async def log_prompt_performance(self, template_id: str, context: dict, quality_score: float, processing_time: float):
        """
        プロンプト性能記録
        """
        performance_record = {
            'template_id': template_id,
            'context_hash': self.hash_context(context),
            'quality_score': quality_score,
            'processing_time': processing_time,
            'timestamp': datetime.now().isoformat(),
            'success': quality_score >= 0.70
        }
        
        # BigQuery にパフォーマンスデータ保存
        await self.save_to_bigquery('prompt_performance', performance_record)
    
    async def analyze_monthly_performance(self) -> dict:
        """
        月次プロンプト性能分析
        """
        query = """
        SELECT 
            template_id,
            AVG(quality_score) as avg_quality,
            AVG(processing_time) as avg_time,
            COUNT(*) as usage_count,
            SUM(CASE WHEN success THEN 1 ELSE 0 END) / COUNT(*) as success_rate
        FROM `manga_service.prompt_performance`
        WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)
        GROUP BY template_id
        ORDER BY avg_quality DESC
        """
        
        results = await self.execute_bigquery(query)
        
        return {
            'top_performing_templates': results[:5],
            'underperforming_templates': [r for r in results if r['avg_quality'] < 0.8],
            'optimization_opportunities': await self.identify_optimization_opportunities(results)
        }
```

---

## 4. 品質制御システム

### 4.1 基本品質評価

#### 品質評価フレームワーク
```python
class QualityEvaluationFramework:
    def __init__(self):
        self.evaluators = {
            'phase1_concept': ConceptAnalysisQualityEvaluator(),
            'phase2_character': CharacterDesignQualityEvaluator(),
            'phase3_plot': PlotStructureQualityEvaluator(),
            'phase4_name': NameGenerationQualityEvaluator(),
            'phase5_scene': SceneImageGenerationQualityEvaluator(),
            'phase6_dialog': DialogPlacementQualityEvaluator(),
            'phase7_final': FinalIntegrationQualityEvaluator()
        }
    
    async def evaluate_phase_quality(self, phase: int, input_data: dict, output_data: dict) -> dict:
        """
        フェーズ品質評価
        """
        agent_type = self.get_agent_type(phase)
        evaluator = self.evaluators[agent_type]
        
        # 基本品質スコア算出
        quality_score = await evaluator.calculate_quality_score(input_data, output_data)
        
        # 品質詳細分析
        quality_breakdown = await evaluator.analyze_quality_components(input_data, output_data)
        
        # 改善提案生成
        improvements = await evaluator.suggest_improvements(input_data, output_data, quality_score)
        
        return {
            'phase': phase,
            'agent_type': agent_type,
            'quality_score': quality_score,
            'passes_gate': quality_score >= 0.85,
            'quality_breakdown': quality_breakdown,
            'improvement_suggestions': improvements,
            'evaluation_timestamp': datetime.now().isoformat()
        }

# Phase 1専用品質評価器
class TextAnalysisQualityEvaluator:
    async def calculate_quality_score(self, input_data: dict, output_data: dict) -> float:
        """
        テキスト解析品質スコア算出
        """
        text = input_data['text']
        analysis = output_data
        
        scores = []
        
        # 1. キャラクター抽出精度 (40%)
        character_score = self.evaluate_character_extraction(text, analysis['characters'])
        scores.append(character_score * 0.4)
        
        # 2. テーマ理解度 (30%)
        theme_score = self.evaluate_theme_understanding(text, analysis['themes'])
        scores.append(theme_score * 0.3)
        
        # 3. 構造認識精度 (30%)
        structure_score = self.evaluate_structure_recognition(text, analysis['chapters'])
        scores.append(structure_score * 0.3)
        
        return sum(scores)
    
    def evaluate_character_extraction(self, text: str, characters: list) -> float:
        """
        キャラクター抽出精度評価
        """
        # 期待キャラクター数の推定
        estimated_characters = self.estimate_character_count(text)
        extracted_count = len(characters)
        
        # 抽出数の適切性
        count_accuracy = min(1.0, extracted_count / max(1, estimated_characters))
        
        # キャラクター名の妥当性チェック
        name_validity = self.check_character_name_validity(characters)
        
        # 重複排除チェック
        uniqueness = len(set(characters)) / len(characters) if characters else 1.0
        
        return (count_accuracy * 0.5) + (name_validity * 0.3) + (uniqueness * 0.2)
```

### 4.2 品質ゲート実装

#### 品質判定ロジック
```python
class QualityGate:
    def __init__(self):
        self.quality_thresholds = {
            'minimum_acceptable': 0.60,  # 最低許容レベル
            'target_quality': 0.70,     # 目標品質レベル
            'exceptional_quality': 0.85  # 優秀品質レベル
        }
        
    async def execute_quality_gate(self, phase: int, input_data: dict, output_data: dict) -> dict:
        """
        品質ゲート実行
        """
        # 品質評価実行
        quality_result = await self.evaluate_quality(phase, input_data, output_data)
        quality_score = quality_result['quality_score']
        
        # 判定処理
        if quality_score >= self.quality_thresholds['target_quality']:
            decision = 'pass'
            action = 'proceed_to_next_phase'
        elif quality_score >= self.quality_thresholds['minimum_acceptable']:
            decision = 'conditional_pass'
            action = 'proceed_with_warning'
        else:
            decision = 'fail'
            action = 'retry_or_escalate'
        
        # 結果記録
        gate_result = {
            'phase': phase,
            'quality_score': quality_score,
            'decision': decision,
            'action': action,
            'quality_breakdown': quality_result['quality_breakdown'],
            'threshold_comparison': {
                'target': self.quality_thresholds['target_quality'],
                'minimum': self.quality_thresholds['minimum_acceptable'],
                'actual': quality_score
            },
            'timestamp': datetime.now().isoformat()
        }
        
        await self.log_quality_gate_result(gate_result)
        return gate_result
```

### 4.3 リトライ機構

#### インテリジェントリトライ
```python
class IntelligentRetryManager:
    def __init__(self):
        self.retry_strategies = {
            'low_quality': 'parameter_adjustment',
            'api_timeout': 'exponential_backoff',
            'api_error': 'alternative_model',
            'content_filter': 'prompt_modification'
        }
    
    async def execute_retry(self, phase: int, failure_reason: str, context: dict) -> dict:
        """
        インテリジェントリトライ実行
        """
        retry_strategy = self.retry_strategies.get(failure_reason, 'standard_retry')
        
        if retry_strategy == 'parameter_adjustment':
            # パラメータ調整リトライ
            modified_context = await self.adjust_parameters(context, failure_reason)
            return await self.execute_phase_with_modified_context(phase, modified_context)
            
        elif retry_strategy == 'prompt_modification':
            # プロンプト修正リトライ
            modified_prompt = await self.modify_prompt_for_retry(context)
            return await self.execute_phase_with_modified_prompt(phase, modified_prompt, context)
            
        else:
            # 標準リトライ
            await asyncio.sleep(self.calculate_backoff_delay(context['retry_count']))
            return await self.execute_standard_retry(phase, context)
    
    async def adjust_parameters(self, context: dict, failure_reason: str) -> dict:
        """
        失敗理由に基づくパラメータ調整
        """
        modified_context = context.copy()
        
        if failure_reason == 'low_quality':
            # 品質向上のためのパラメータ調整
            if context.get('temperature'):
                modified_context['temperature'] = max(0.1, context['temperature'] - 0.2)
            if context.get('max_tokens'):
                modified_context['max_tokens'] = min(4000, context['max_tokens'] + 500)
        
        return modified_context
```

---

## 5. AI学習・改善システム

### 5.1 HITLフィードバック学習

#### HITLフィードバック収集システム
```python
class HITLFeedbackLearningSystem:
    def __init__(self):
        self.feedback_channels = {
            'realtime_hitl': RealtimeHITLCollector(),
            'phase_feedback': PhaseFeedbackCollector(),
            'natural_language': NaturalLanguageFeedbackCollector(),
            'interaction_patterns': InteractionPatternCollector()
        }
        self.learning_engine = HITLLearningEngine()
        
    async def collect_hitl_session_feedback(self, request_id: str) -> dict:
        """
        HITLセッション総合フィードバック収集
        """
        feedback_data = {}
        
        # 1. リアルタイムHITLフィードバック収集
        feedback_data['hitl_interactions'] = await self.feedback_channels['realtime_hitl'].collect(request_id)
        
        # 2. フェーズ別フィードバック分析
        feedback_data['phase_feedback'] = await self.feedback_channels['phase_feedback'].collect(request_id)
        
        # 3. 自然言語フィードバック解析
        feedback_data['natural_language_insights'] = await self.feedback_channels['natural_language'].collect(request_id)
        
        # 4. ユーザーインタラクションパターン
        feedback_data['interaction_patterns'] = await self.feedback_channels['interaction_patterns'].collect(request_id)
        
        # 5. HITL学習データ統合
        learning_data = await self.learning_engine.integrate_hitl_feedback(feedback_data)
        
        # 6. AI改善機会特定
        ai_improvements = await self.identify_ai_improvement_opportunities(learning_data)
        
        return {
            'request_id': request_id,
            'hitl_feedback_data': feedback_data,
            'learning_insights': learning_data,
            'ai_improvement_opportunities': ai_improvements,
            'user_satisfaction_score': learning_data.get('overall_satisfaction', 0.8),
            'collection_timestamp': datetime.now().isoformat()
        }

class UserRatingCollector:
    async def collect(self, request_id: str) -> dict:
        """
        ユーザー評価収集
        """
        # ユーザー評価データベースから取得
        rating_data = await self.get_user_rating(request_id)
        
        if rating_data:
            return {
                'overall_rating': rating_data['rating'],
                'specific_ratings': {
                    'story_quality': rating_data.get('story', 3),
                    'art_quality': rating_data.get('art', 3),
                    'character_design': rating_data.get('characters', 3),
                    'layout_quality': rating_data.get('layout', 3)
                },
                'text_feedback': rating_data.get('comments', ''),
                'rating_timestamp': rating_data['created_at']
            }
        else:
            # 評価待ち（30日後に再収集）
            return {'status': 'pending', 'retry_after': 30 * 24 * 3600}
```

### 5.2 基本改善プロセス

#### 月次改善サイクル
```python
class BasicImprovementProcess:
    def __init__(self):
        self.feedback_analyzer = FeedbackAnalyzer()
        self.improvement_executor = ImprovementExecutor()
        
    async def execute_monthly_improvement_cycle(self) -> dict:
        """
        月次改善サイクル実行
        """
        print("=== 月次AI改善サイクル開始 ===")
        
        # 1. 過去30日のデータ収集
        monthly_data = await self.collect_monthly_feedback_data()
        
        # 2. パフォーマンス分析
        performance_analysis = await self.analyze_monthly_performance(monthly_data)
        
        # 3. 改善機会特定
        improvement_opportunities = await self.identify_improvement_opportunities(performance_analysis)
        
        # 4. 改善計画作成
        improvement_plan = await self.create_improvement_plan(improvement_opportunities)
        
        # 5. 安全な改善の自動実行
        auto_improvements = [imp for imp in improvement_plan if imp['risk_level'] == 'low']
        executed_improvements = []
        
        for improvement in auto_improvements:
            try:
                result = await self.improvement_executor.execute_improvement(improvement)
                executed_improvements.append({
                    'improvement': improvement,
                    'result': result,
                    'status': 'success'
                })
            except Exception as e:
                executed_improvements.append({
                    'improvement': improvement,
                    'error': str(e),
                    'status': 'failed'
                })
        
        # 6. 手動レビュー必要な改善のレポート
        manual_review_needed = [imp for imp in improvement_plan if imp['risk_level'] != 'low']
        
        return {
            'analysis_period': '30 days',
            'total_requests_analyzed': monthly_data['total_requests'],
            'performance_summary': performance_analysis['summary'],
            'improvement_opportunities': len(improvement_opportunities),
            'auto_executed_improvements': len(executed_improvements),
            'manual_review_needed': len(manual_review_needed),
            'manual_review_items': manual_review_needed
        }
    
    async def identify_improvement_opportunities(self, performance_data: dict) -> list:
        """
        改善機会特定
        """
        opportunities = []
        
        # 品質スコア分析
        for phase, metrics in performance_data['phase_metrics'].items():
            if metrics['avg_quality_score'] < 0.80:
                opportunities.append({
                    'type': 'quality_improvement',
                    'phase': phase,
                    'current_score': metrics['avg_quality_score'],
                    'target_score': 0.85,
                    'risk_level': 'low',
                    'estimated_impact': 'medium'
                })
        
        # 処理時間分析
        for phase, metrics in performance_data['phase_metrics'].items():
            if metrics['avg_processing_time'] > metrics['time_limit'] * 0.8:
                opportunities.append({
                    'type': 'performance_optimization',
                    'phase': phase,
                    'current_time': metrics['avg_processing_time'],
                    'target_time': metrics['time_limit'] * 0.7,
                    'risk_level': 'medium',
                    'estimated_impact': 'high'
                })
        
        return opportunities
```

### 5.3 統計分析

#### AI性能統計分析
```python
class AIPerformanceStatistics:
    def __init__(self):
        self.bigquery_client = bigquery.Client()
        
    async def generate_monthly_ai_report(self) -> dict:
        """
        月次AI性能レポート生成
        """
        # 1. 基本統計
        basic_stats = await self.calculate_basic_statistics()
        
        # 2. 品質トレンド分析
        quality_trends = await self.analyze_quality_trends()
        
        # 3. ユーザー満足度分析
        user_satisfaction = await self.analyze_user_satisfaction()
        
        # 4. コスト効率分析
        cost_efficiency = await self.analyze_cost_efficiency()
        
        # 5. 技術的指標
        technical_metrics = await self.calculate_technical_metrics()
        
        return {
            'report_period': 'monthly',
            'basic_statistics': basic_stats,
            'quality_trends': quality_trends,
            'user_satisfaction': user_satisfaction,
            'cost_efficiency': cost_efficiency,
            'technical_metrics': technical_metrics,
            'key_insights': await self.extract_key_insights(basic_stats, quality_trends, user_satisfaction),
            'recommendations': await self.generate_monthly_recommendations(quality_trends, user_satisfaction)
        }
    
    async def calculate_basic_statistics(self) -> dict:
        """
        基本統計計算
        """
        query = """
        SELECT 
            COUNT(*) as total_requests,
            AVG(overall_quality_score) as avg_quality,
            AVG(total_processing_time) as avg_processing_time,
            SUM(CASE WHEN status = 'success' THEN 1 ELSE 0 END) / COUNT(*) as success_rate,
            COUNT(DISTINCT user_id) as unique_users
        FROM `manga_service.ai_processing_logs`
        WHERE DATE(timestamp) >= DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY)
        """
        
        result = await self.execute_query(query)
        return result[0] if result else {}
```

---

## 6. 外部AI API統合設計

### 6.1 Google Gemini Pro統合

#### Gemini Pro最適化設定
```python
class GeminiProIntegration:
    def __init__(self):
        self.client = self.initialize_gemini_client()
        self.optimization_settings = {
            'phase1_concept': {
                'temperature': 0.3,      # 一貫した分析のため低温度
                'top_p': 0.8,
                'max_tokens': 2048,
                'safety_settings': 'block_medium_and_above'
            },
            'phase3_plot': {
                'temperature': 0.5,      # 創造性と構造のバランス
                'top_p': 0.9,
                'max_tokens': 3072,
                'safety_settings': 'block_medium_and_above'
            },
            'character_design': {
                'temperature': 0.7,      # 創造的なキャラクター設定
                'top_p': 0.9,
                'max_tokens': 2048,
                'safety_settings': 'block_medium_and_above'
            }
        }
    
    async def generate_with_optimization(self, agent_type: str, prompt: str, context: dict) -> dict:
        """
        最適化設定でのGemini Pro呼び出し
        """
        settings = self.optimization_settings.get(agent_type, self.optimization_settings['phase1_concept'])
        
        # A/Bテスト用設定調整
        if context.get('ab_test_variant'):
            settings = self.apply_ab_test_modifications(settings, context['ab_test_variant'])
        
        try:
            response = await self.client.generate_content(
                prompt,
                generation_config={
                    'temperature': settings['temperature'],
                    'top_p': settings['top_p'],
                    'max_output_tokens': settings['max_tokens']
                },
                safety_settings=self.get_safety_settings(settings['safety_settings'])
            )
            
            return {
                'content': response.text,
                'usage_metadata': {
                    'prompt_token_count': response.usage_metadata.prompt_token_count,
                    'candidates_token_count': response.usage_metadata.candidates_token_count,
                    'total_token_count': response.usage_metadata.total_token_count
                },
                'settings_used': settings
            }
            
        except Exception as e:
            await self.log_api_error('gemini_pro', str(e), context)
            raise AIAPIError(f"Gemini Pro API error: {str(e)}")
```

### 6.2 Google Imagen 4統合

#### Imagen 4最適化設定
```python
class Imagen4Integration:
    def __init__(self):
        self.client = self.initialize_imagen_client()
        self.style_presets = {
            '少年漫画': {
                'style_description': 'Japanese shonen manga style, dynamic action, bold lines, vibrant colors',
                'negative_prompts': ['photorealistic', 'western comic', 'realistic rendering'],
                'aspect_ratio': '4:3',
                'quality': 'high'
            },
            '少女漫画': {
                'style_description': 'Japanese shoujo manga style, delicate lines, soft colors, emotional expression',
                'negative_prompts': ['dark', 'violent', 'masculine'],
                'aspect_ratio': '4:3', 
                'quality': 'high'
            },
            'アメコミ': {
                'style_description': 'American comic book style, bold colors, dramatic shadows, superhero aesthetic',
                'negative_prompts': ['anime', 'manga', 'japanese'],
                'aspect_ratio': '3:4',
                'quality': 'high'
            }
        }
    
    async def generate_manga_image(self, scene_prompt: str, style: str, context: dict) -> dict:
        """
        漫画画像生成
        """
        style_preset = self.style_presets.get(style, self.style_presets['少年漫画'])
        
        # 完全なプロンプト構築
        full_prompt = self.build_complete_prompt(scene_prompt, style_preset, context)
        
        try:
            response = await self.client.generate_images(
                prompt=full_prompt,
                number_of_images=1,
                aspect_ratio=style_preset['aspect_ratio'],
                negative_prompt=', '.join(style_preset['negative_prompts']),
                safety_filter_level='block_some',
                person_generation='allow_adult'  # 成人キャラクターのみ
            )
            
            return {
                'image_url': response.images[0].gcs_uri,
                'prompt_used': full_prompt,
                'style_applied': style,
                'generation_metadata': {
                    'generation_time': response.generation_time,
                    'safety_ratings': response.images[0].safety_ratings
                }
            }
            
        except Exception as e:
            await self.log_api_error('imagen_4', str(e), context)
            raise AIAPIError(f"Imagen 4 API error: {str(e)}")
    
    def build_complete_prompt(self, scene_prompt: str, style_preset: dict, context: dict) -> str:
        """
        完全なプロンプト構築
        """
        # 基本プロンプト
        base_prompt = f"{scene_prompt}, {style_preset['style_description']}"
        
        # コンテキスト情報追加
        if context.get('characters'):
            character_info = ', '.join([f"{char['name']} ({char['description']})" for char in context['characters']])
            base_prompt += f", featuring characters: {character_info}"
        
        if context.get('setting'):
            base_prompt += f", setting: {context['setting']}"
        
        if context.get('mood'):
            base_prompt += f", mood: {context['mood']}"
        
        # 品質向上プロンプト
        base_prompt += ", high quality, professional manga artwork, clean lines, proper anatomy"
        
        return base_prompt
```

### 6.3 APIレート制限管理

#### インテリジェントレート制限
```python
class IntelligentRateLimitManager:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.api_quotas = {
            'gemini_pro': {'daily_limit': 7000, 'burst_limit': 100},
            'imagen_4': {'daily_limit': 3000, 'burst_limit': 10}
        }
        self.usage_prediction = UsagePredictionModel()
        
    async def smart_rate_limit_check(self, api_name: str, estimated_usage: int = 1) -> dict:
        """
        インテリジェントレート制限チェック
        """
        current_usage = await self.get_current_usage(api_name)
        daily_limit = self.api_quotas[api_name]['daily_limit']
        
        # 使用量予測
        predicted_daily_usage = await self.usage_prediction.predict_daily_usage(
            api_name, current_usage, datetime.now().hour
        )
        
        # 制限判定
        if current_usage + estimated_usage > daily_limit:
            return {
                'allowed': False,
                'reason': 'daily_limit_exceeded',
                'retry_after': self.calculate_reset_time()
            }
        
        # 予測的制限
        if predicted_daily_usage > daily_limit * 0.9:  # 90%予測で警告
            return {
                'allowed': True,
                'warning': 'approaching_daily_limit',
                'predicted_usage': predicted_daily_usage,
                'recommendation': 'consider_usage_optimization'
            }
        
        # 通常処理
        await self.increment_usage(api_name, estimated_usage)
        
        return {
            'allowed': True,
            'current_usage': current_usage + estimated_usage,
            'remaining_quota': daily_limit - (current_usage + estimated_usage)
        }
    
    async def optimize_api_usage(self, request_queue: list) -> list:
        """
        API使用量最適化
        """
        # バッチ処理可能なリクエスト特定
        batchable_requests = self.identify_batchable_requests(request_queue)
        
        # 優先度による処理順序最適化
        prioritized_queue = self.prioritize_requests(request_queue)
        
        # 時間分散によるレート制限回避
        time_distributed_queue = self.distribute_requests_over_time(prioritized_queue)
        
        return time_distributed_queue
```

---

## 7. AI処理パフォーマンス設計

### 7.1 処理時間最適化

#### フェーズ別パフォーマンス最適化
```python
class AIPerformanceOptimizer:
    def __init__(self):
        self.phase_optimizers = {
            1: TextAnalysisOptimizer(),
            2: StoryStructureOptimizer(),
            3: SceneDivisionOptimizer(),
            4: CharacterDesignOptimizer(),
            5: PanelLayoutOptimizer(),
            6: ImageGenerationOptimizer(),
            7: DialogPlacementOptimizer(),
            8: FinalIntegrationOptimizer()
        }
        
    async def optimize_phase_performance(self, phase: int, context: dict) -> dict:
        """
        フェーズ別パフォーマンス最適化
        """
        optimizer = self.phase_optimizers[phase]
        
        # コンテキスト分析による最適化戦略決定
        optimization_strategy = await optimizer.determine_optimization_strategy(context)
        
        # 最適化パラメータ適用
        optimized_params = await optimizer.apply_optimization(optimization_strategy, context)
        
        return optimized_params

class ImageGenerationOptimizer:
    """
    画像生成最適化（最も重い処理）
    """
    
    async def determine_optimization_strategy(self, context: dict) -> dict:
        """
        画像生成最適化戦略決定
        """
        scene_count = len(context.get('scenes', []))
        complexity = context.get('complexity', 'medium')
        
        if scene_count > 30:
            # 大量画像生成 - バッチ処理
            strategy = 'batch_processing'
        elif complexity == 'high':
            # 高複雑度 - 段階的生成
            strategy = 'progressive_generation'
        else:
            # 標準処理
            strategy = 'standard_processing'
        
        return {
            'strategy': strategy,
            'batch_size': self.calculate_optimal_batch_size(scene_count),
            'parallel_workers': self.calculate_parallel_workers(complexity),
            'quality_vs_speed_tradeoff': 0.8  # 80% 品質重視
        }
    
    async def apply_optimization(self, strategy: dict, context: dict) -> dict:
        """
        最適化パラメータ適用
        """
        if strategy['strategy'] == 'batch_processing':
            return {
                'processing_mode': 'batch',
                'batch_size': strategy['batch_size'],
                'concurrent_batches': strategy['parallel_workers'],
                'timeout_per_batch': 300  # 5分/バッチ
            }
        elif strategy['strategy'] == 'progressive_generation':
            return {
                'processing_mode': 'progressive',
                'quality_steps': [0.7, 0.85, 0.95],  # 段階的品質向上
                'early_termination': True  # 十分な品質で早期終了
            }
        else:
            return {
                'processing_mode': 'standard',
                'timeout': 180,
                'quality_target': 0.85
            }
```

### 7.2 並列処理設計

#### 安全な並列処理
```python
class SafeParallelProcessor:
    def __init__(self):
        self.semaphore_limits = {
            'gemini_pro': 5,    # 同時5リクエストまで
            'imagen_4': 2       # 同時2リクエストまで
        }
        self.semaphores = {
            api: asyncio.Semaphore(limit) 
            for api, limit in self.semaphore_limits.items()
        }
    
    async def process_scenes_in_parallel(self, scenes: list, agent: ImageGenerationAgent) -> list:
        """
        シーンの並列処理
        """
        # セマフォで同時実行数制限
        async def process_single_scene(scene):
            async with self.semaphores['imagen_4']:
                return await agent.generate_scene_image(scene)
        
        # 並列実行
        tasks = [process_single_scene(scene) for scene in scenes]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # エラーハンドリング
        successful_results = []
        failed_scenes = []
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                failed_scenes.append((i, scenes[i], str(result)))
            else:
                successful_results.append(result)
        
        # 失敗シーンの再処理
        if failed_scenes:
            retry_results = await self.retry_failed_scenes(failed_scenes, agent)
            successful_results.extend(retry_results)
        
        return successful_results
```

### 7.3 リソース効率化

#### AIリソース管理
```python
class AIResourceManager:
    def __init__(self):
        self.resource_monitor = ResourceMonitor()
        self.cost_optimizer = CostOptimizer()
        
    async def optimize_resource_allocation(self, pending_requests: list) -> dict:
        """
        リソース配分最適化
        """
        # 現在のリソース使用状況
        current_usage = await self.resource_monitor.get_current_usage()
        
        # リクエスト優先度付け
        prioritized_requests = await self.prioritize_requests(pending_requests)
        
        # リソース配分計画
        allocation_plan = await self.create_allocation_plan(prioritized_requests, current_usage)
        
        return allocation_plan
    
    async def prioritize_requests(self, requests: list) -> list:
        """
        リクエスト優先度付け
        """
        def calculate_priority(request):
            priority_score = 0
            
            # ユーザータイプによる優先度
            if request['user_type'] == 'premium':
                priority_score += 10
            elif request['user_type'] == 'free':
                priority_score += 5
            
            # 待機時間による優先度
            wait_time = datetime.now() - request['submitted_at']
            priority_score += min(10, wait_time.total_seconds() / 300)  # 5分で1ポイント
            
            # テキスト長による調整（短いテキストを優先）
            text_length = len(request.get('text', ''))
            if text_length < 1000:
                priority_score += 3
            elif text_length > 10000:
                priority_score -= 2
            
            return priority_score
        
        return sorted(requests, key=calculate_priority, reverse=True)
```

---

## 8. AI倫理・安全性設計

### 8.1 コンテンツ安全性

#### AI生成コンテンツ安全性チェック
```python
class AIContentSafetyChecker:
    def __init__(self):
        self.safety_models = {
            'text_safety': TextSafetyModel(),
            'image_safety': ImageSafetyModel(),
            'content_appropriateness': ContentAppropriatenessModel()
        }
        
    async def comprehensive_safety_check(self, generated_content: dict) -> dict:
        """
        包括的安全性チェック
        """
        safety_results = {}
        
        # テキストコンテンツ安全性
        if 'text_content' in generated_content:
            safety_results['text_safety'] = await self.safety_models['text_safety'].check(
                generated_content['text_content']
            )
        
        # 画像コンテンツ安全性
        if 'images' in generated_content:
            image_safety_results = []
            for image in generated_content['images']:
                image_result = await self.safety_models['image_safety'].check(image['url'])
                image_safety_results.append(image_result)
            safety_results['image_safety'] = image_safety_results
        
        # 総合コンテンツ適切性
        safety_results['overall_appropriateness'] = await self.safety_models['content_appropriateness'].check(
            generated_content
        )
        
        # 安全性総合判定
        overall_safe = self.calculate_overall_safety(safety_results)
        
        return {
            'is_safe': overall_safe,
            'safety_results': safety_results,
            'safety_score': self.calculate_safety_score(safety_results),
            'flagged_issues': self.extract_flagged_issues(safety_results)
        }
```

### 8.2 バイアス軽減

#### AIバイアス検出・軽減
```python
class BiasDetectionSystem:
    def __init__(self):
        self.bias_detectors = {
            'gender_bias': GenderBiasDetector(),
            'cultural_bias': CulturalBiasDetector(),
            'age_bias': AgeBiasDetector()
        }
        
    async def detect_potential_bias(self, generated_content: dict, original_input: dict) -> dict:
        """
        潜在的バイアス検出
        """
        bias_analysis = {}
        
        # 各種バイアス検出
        for bias_type, detector in self.bias_detectors.items():
            bias_result = await detector.analyze(generated_content, original_input)
            bias_analysis[bias_type] = bias_result
        
        # バイアス総合評価
        overall_bias_score = self.calculate_overall_bias_score(bias_analysis)
        
        # 軽減提案生成
        mitigation_suggestions = await self.generate_bias_mitigation_suggestions(bias_analysis)
        
        return {
            'bias_detected': overall_bias_score > 0.5,
            'bias_score': overall_bias_score,
            'bias_analysis': bias_analysis,
            'mitigation_suggestions': mitigation_suggestions
        }

class GenderBiasDetector:
    async def analyze(self, content: dict, input_data: dict) -> dict:
        """
        ジェンダーバイアス分析
        """
        characters = content.get('characters', [])
        
        # 性別バランス分析
        gender_distribution = self.analyze_gender_distribution(characters)
        
        # 役割バイアス分析
        role_bias = self.analyze_role_bias(characters)
        
        # 描写バイアス分析
        portrayal_bias = self.analyze_portrayal_bias(characters)
        
        return {
            'gender_distribution': gender_distribution,
            'role_bias_score': role_bias,
            'portrayal_bias_score': portrayal_bias,
            'overall_bias_score': (role_bias + portrayal_bias) / 2
        }
```

### 8.3 透明性確保

#### AI決定プロセスの透明性
```python
class AITransparencyManager:
    def __init__(self):
        self.decision_logger = DecisionLogger()
        self.explanation_generator = ExplanationGenerator()
        
    async def log_ai_decision(self, phase: int, input_data: dict, output_data: dict, decision_factors: dict):
        """
        AI決定プロセスのログ記録
        """
        decision_log = {
            'phase': phase,
            'request_id': input_data.get('request_id'),
            'decision_timestamp': datetime.now().isoformat(),
            'input_summary': self.summarize_input(input_data),
            'output_summary': self.summarize_output(output_data),
            'decision_factors': decision_factors,
            'quality_score': output_data.get('quality_score'),
            'processing_time': output_data.get('processing_time')
        }
        
        await self.decision_logger.log(decision_log)
    
    async def generate_user_explanation(self, request_id: str, phase: int) -> dict:
        """
        ユーザー向け説明生成
        """
        # 決定ログ取得
        decision_logs = await self.decision_logger.get_decision_logs(request_id, phase)
        
        # 分かりやすい説明生成
        explanation = await self.explanation_generator.create_user_friendly_explanation(
            phase, decision_logs
        )
        
        return {
            'phase': phase,
            'explanation': explanation,
            'confidence_level': decision_logs.get('confidence', 0.8),
            'alternative_approaches': await self.get_alternative_approaches(decision_logs)
        }
```


---

## 改訂履歴

| 版数 | 日付 | 変更内容 | 担当者 |
|------|------|----------|--------|
| 1.0 | 2025-01-20 | 初版作成（7フェーズ独立エージェント型、動的プロンプト管理） | Claude Code |
| 2.0 | 2025-01-24 | HITL（Human-in-the-loop）システム統合対応：<br>・7フェーズインタラクティブ処理システム<br>・ユーザーフィードバック機能追加<br>・リアルタイム協調処理設計<br>・30分タイムアウト機能<br>・自然言語フィードバック処理<br>・WebSocket通信システム<br>・フェーズ別プレビュー機能 | Claude Code |

---

**文書承認**
- AIアーキテクト: [署名] 日付: [日付]
- MLエンジニア: [署名] 日付: [日付]
- プロダクトマネージャー: [署名] 日付: [日付]