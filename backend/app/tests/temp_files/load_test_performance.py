#!/usr/bin/env python3
"""
AIæ¼«ç”»ç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹ è² è·ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼ã‚’è¡Œã„ã¾ã™ï¼š
1. åŒæ™‚10ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã®ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆ
2. APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“æ¸¬å®š
3. WebSocketæ¥ç¶šã®å®‰å®šæ€§ãƒ†ã‚¹ãƒˆ
4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è² è·ãƒ†ã‚¹ãƒˆ
5. å“è³ªã‚²ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®è² è·è€æ€§
6. ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ©Ÿèƒ½ã®è² è·è€æ€§
"""

import asyncio
import aiohttp
import websockets
import json
import time
import statistics
import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
from uuid import uuid4
from dataclasses import dataclass
import concurrent.futures
import psutil
import gc

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ãƒ†ã‚¹ãƒˆè¨­å®š
BASE_API_URL = "http://localhost:8000/api/v1"
BASE_WS_URL = "ws://localhost:8000/ws/v1"
TEST_TOKEN = "test-jwt-token"
CONCURRENT_USERS = 10
TEST_DURATION_SECONDS = 300  # 5åˆ†é–“
RAMP_UP_TIME_SECONDS = 30   # 30ç§’ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ®µéšçš„ã«å¢—åŠ 

@dataclass
class PerformanceMetrics:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    response_times: List[float]
    error_count: int
    success_count: int
    throughput: float
    memory_usage: float
    cpu_usage: float
    
    @property
    def avg_response_time(self) -> float:
        return statistics.mean(self.response_times) if self.response_times else 0.0
    
    @property
    def p95_response_time(self) -> float:
        return statistics.quantiles(self.response_times, n=20)[18] if len(self.response_times) >= 20 else 0.0
    
    @property
    def p99_response_time(self) -> float:
        return statistics.quantiles(self.response_times, n=100)[98] if len(self.response_times) >= 100 else 0.0
    
    @property
    def success_rate(self) -> float:
        total = self.success_count + self.error_count
        return (self.success_count / total * 100) if total > 0 else 0.0


class LoadTester:
    """è² è·ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.results = {}
        self.active_users = 0
        self.start_time = None
        self.system_metrics = []
        
    async def run_comprehensive_load_test(self):
        """åŒ…æ‹¬çš„ãªè² è·ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
        logger.info("=== AIæ¼«ç”»ç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹ è² è·ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
        logger.info(f"åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {CONCURRENT_USERS}")
        logger.info(f"ãƒ†ã‚¹ãƒˆæ™‚é–“: {TEST_DURATION_SECONDS}ç§’")
        logger.info(f"ãƒ©ãƒ³ãƒ—ã‚¢ãƒƒãƒ—æ™‚é–“: {RAMP_UP_TIME_SECONDS}ç§’")
        
        self.start_time = time.time()
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–ã‚¿ã‚¹ã‚¯
        monitor_task = asyncio.create_task(self.monitor_system_resources())
        
        try:
            # ä¸¦è¡Œãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            test_tasks = [
                self.test_api_endpoints_load(),
                self.test_websocket_connections_load(),
                self.test_quality_gates_load(),
                self.test_preview_interactive_load(),
                self.test_database_load()
            ]
            
            # ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’ä¸¦è¡Œå®Ÿè¡Œ
            results = await asyncio.gather(*test_tasks, return_exceptions=True)
            
            # çµæœã®å‡¦ç†
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"ãƒ†ã‚¹ãƒˆ{i}ã§ã‚¨ãƒ©ãƒ¼: {result}")
                else:
                    self.results[f"test_{i}"] = result
                    
        except Exception as e:
            logger.error(f"è² è·ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–åœæ­¢
            monitor_task.cancel()
            try:
                await monitor_task
            except asyncio.CancelledError:
                pass
            
        # çµæœåˆ†æã¨è¡¨ç¤º
        await self.analyze_and_report_results()
    
    async def test_api_endpoints_load(self) -> Dict[str, Any]:
        """API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè² è·ãƒ†ã‚¹ãƒˆ"""
        logger.info("--- API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè² è·ãƒ†ã‚¹ãƒˆé–‹å§‹ ---")
        
        endpoints = [
            {"method": "GET", "path": "/info", "name": "api_info"},
            {"method": "GET", "path": "/health", "name": "health_check"},
            {"method": "POST", "path": "/manga/generate", "name": "manga_generate", 
             "data": {"input_text": "ãƒ†ã‚¹ãƒˆç”¨ãƒãƒ³ã‚¬ç”Ÿæˆ", "hitl_enabled": False}},
            {"method": "GET", "path": "/quality/health", "name": "quality_health"}
        ]
        
        metrics = {endpoint["name"]: PerformanceMetrics([], 0, 0, 0.0, 0.0, 0.0) 
                  for endpoint in endpoints}
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯
        async def simulate_user(user_id: int):
            async with aiohttp.ClientSession() as session:
                user_start_time = time.time()
                requests_made = 0
                
                while time.time() - user_start_time < TEST_DURATION_SECONDS:
                    for endpoint in endpoints:
                        try:
                            request_start = time.time()
                            
                            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œ
                            if endpoint["method"] == "GET":
                                async with session.get(
                                    f"{BASE_API_URL}{endpoint['path']}",
                                    headers={"Authorization": f"Bearer {TEST_TOKEN}"},
                                    timeout=aiohttp.ClientTimeout(total=30)
                                ) as response:
                                    await response.text()
                                    status_ok = response.status < 400
                            else:  # POST
                                async with session.post(
                                    f"{BASE_API_URL}{endpoint['path']}",
                                    json=endpoint.get("data", {}),
                                    headers={"Authorization": f"Bearer {TEST_TOKEN}"},
                                    timeout=aiohttp.ClientTimeout(total=30)
                                ) as response:
                                    await response.text()
                                    status_ok = response.status < 400
                            
                            request_time = time.time() - request_start
                            
                            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
                            endpoint_metrics = metrics[endpoint["name"]]
                            endpoint_metrics.response_times.append(request_time)
                            
                            if status_ok:
                                endpoint_metrics.success_count += 1
                            else:
                                endpoint_metrics.error_count += 1
                                
                            requests_made += 1
                            
                        except Exception as e:
                            metrics[endpoint["name"]].error_count += 1
                            logger.debug(f"User {user_id} request error: {e}")
                        
                        # çŸ­ã„å¾…æ©Ÿ
                        await asyncio.sleep(0.1)
                    
                    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”
                    await asyncio.sleep(1.0)
                
                logger.debug(f"User {user_id} completed {requests_made} requests")
        
        # æ®µéšçš„ãƒ¦ãƒ¼ã‚¶ãƒ¼èµ·å‹•
        user_tasks = []
        for i in range(CONCURRENT_USERS):
            # ãƒ©ãƒ³ãƒ—ã‚¢ãƒƒãƒ—é…å»¶
            await asyncio.sleep(RAMP_UP_TIME_SECONDS / CONCURRENT_USERS)
            task = asyncio.create_task(simulate_user(i))
            user_tasks.append(task)
            self.active_users += 1
            logger.info(f"APIè² è·ãƒ†ã‚¹ãƒˆ: ãƒ¦ãƒ¼ã‚¶ãƒ¼{i+1}é–‹å§‹ (ç·{self.active_users}ãƒ¦ãƒ¼ã‚¶ãƒ¼)")
        
        # ã™ã¹ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ã‚¹ã‚¯å®Œäº†å¾…æ©Ÿ
        await asyncio.gather(*user_tasks, return_exceptions=True)
        
        # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—
        total_time = TEST_DURATION_SECONDS
        for endpoint_name, metric in metrics.items():
            total_requests = metric.success_count + metric.error_count
            metric.throughput = total_requests / total_time if total_time > 0 else 0
        
        logger.info("âœ… API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè² è·ãƒ†ã‚¹ãƒˆå®Œäº†")
        return {"api_endpoints": metrics}
    
    async def test_websocket_connections_load(self) -> Dict[str, Any]:
        """WebSocketæ¥ç¶šè² è·ãƒ†ã‚¹ãƒˆ"""
        logger.info("--- WebSocketæ¥ç¶šè² è·ãƒ†ã‚¹ãƒˆé–‹å§‹ ---")
        
        connection_metrics = PerformanceMetrics([], 0, 0, 0.0, 0.0, 0.0)
        message_metrics = PerformanceMetrics([], 0, 0, 0.0, 0.0, 0.0)
        
        # WebSocketãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        async def simulate_websocket_user(user_id: int):
            session_id = str(uuid4())
            connection_start = time.time()
            messages_sent = 0
            
            try:
                # WebSocketæ¥ç¶š
                async with websockets.connect(
                    f"{BASE_WS_URL}/sessions/{session_id}",
                    extra_headers={"Authorization": f"Bearer {TEST_TOKEN}"},
                    timeout=10
                ) as websocket:
                    
                    connection_time = time.time() - connection_start
                    connection_metrics.response_times.append(connection_time)
                    connection_metrics.success_count += 1
                    
                    # èªè¨¼
                    await websocket.send(json.dumps({
                        "type": "authenticate",
                        "token": TEST_TOKEN
                    }))
                    
                    auth_response = await asyncio.wait_for(websocket.recv(), timeout=5.0)
                    auth_data = json.loads(auth_response)
                    
                    if auth_data.get("type") != "authenticated":
                        connection_metrics.error_count += 1
                        return
                    
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€å—ä¿¡ãƒ†ã‚¹ãƒˆ
                    user_start_time = time.time()
                    while time.time() - user_start_time < TEST_DURATION_SECONDS:
                        try:
                            message_start = time.time()
                            
                            # Pingãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
                            ping_message = {
                                "type": "ping",
                                "user_id": user_id,
                                "timestamp": datetime.utcnow().isoformat()
                            }
                            
                            await websocket.send(json.dumps(ping_message))
                            
                            # Pongãƒ¬ã‚¹ãƒãƒ³ã‚¹å¾…æ©Ÿ
                            response = await asyncio.wait_for(websocket.recv(), timeout=5.0)
                            response_data = json.loads(response)
                            
                            message_time = time.time() - message_start
                            message_metrics.response_times.append(message_time)
                            
                            if response_data.get("type") == "pong":
                                message_metrics.success_count += 1
                            else:
                                message_metrics.error_count += 1
                            
                            messages_sent += 1
                            
                        except Exception as e:
                            message_metrics.error_count += 1
                            logger.debug(f"WebSocket user {user_id} message error: {e}")
                        
                        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é–“éš”
                        await asyncio.sleep(2.0)
                    
            except Exception as e:
                connection_metrics.error_count += 1
                logger.debug(f"WebSocket user {user_id} connection error: {e}")
            
            logger.debug(f"WebSocket user {user_id} sent {messages_sent} messages")
        
        # æ®µéšçš„WebSocketãƒ¦ãƒ¼ã‚¶ãƒ¼èµ·å‹•
        ws_tasks = []
        for i in range(CONCURRENT_USERS):
            await asyncio.sleep(RAMP_UP_TIME_SECONDS / CONCURRENT_USERS)
            task = asyncio.create_task(simulate_websocket_user(i))
            ws_tasks.append(task)
            logger.info(f"WebSocketè² è·ãƒ†ã‚¹ãƒˆ: ãƒ¦ãƒ¼ã‚¶ãƒ¼{i+1}æ¥ç¶šé–‹å§‹")
        
        # ã™ã¹ã¦ã®WebSocketã‚¿ã‚¹ã‚¯å®Œäº†å¾…æ©Ÿ
        await asyncio.gather(*ws_tasks, return_exceptions=True)
        
        logger.info("âœ… WebSocketæ¥ç¶šè² è·ãƒ†ã‚¹ãƒˆå®Œäº†")
        return {
            "websocket_connections": connection_metrics,
            "websocket_messages": message_metrics
        }
    
    async def test_quality_gates_load(self) -> Dict[str, Any]:
        """å“è³ªã‚²ãƒ¼ãƒˆè² è·ãƒ†ã‚¹ãƒˆ"""
        logger.info("--- å“è³ªã‚²ãƒ¼ãƒˆè² è·ãƒ†ã‚¹ãƒˆé–‹å§‹ ---")
        
        quality_metrics = PerformanceMetrics([], 0, 0, 0.0, 0.0, 0.0)
        
        # å“è³ªã‚²ãƒ¼ãƒˆAPIãƒ†ã‚¹ãƒˆ
        async def test_quality_endpoints(session: aiohttp.ClientSession):
            test_session_id = str(uuid4())
            
            endpoints = [
                f"/manga/{test_session_id}/quality-gate",
                "/quality/metrics", 
                "/quality/health"
            ]
            
            for endpoint in endpoints:
                try:
                    request_start = time.time()
                    
                    async with session.get(
                        f"{BASE_API_URL}{endpoint}",
                        headers={"Authorization": f"Bearer {TEST_TOKEN}"},
                        timeout=aiohttp.ClientTimeout(total=15)
                    ) as response:
                        await response.text()
                        
                        request_time = time.time() - request_start
                        quality_metrics.response_times.append(request_time)
                        
                        if response.status < 400:
                            quality_metrics.success_count += 1
                        else:
                            quality_metrics.error_count += 1
                            
                except Exception as e:
                    quality_metrics.error_count += 1
                    logger.debug(f"Quality gate test error: {e}")
        
        # ä¸¦è¡Œå“è³ªã‚²ãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
        async with aiohttp.ClientSession() as session:
            quality_tasks = []
            for _ in range(CONCURRENT_USERS * 3):  # ã‚ˆã‚Šå¤šãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
                task = asyncio.create_task(test_quality_endpoints(session))
                quality_tasks.append(task)
            
            await asyncio.gather(*quality_tasks, return_exceptions=True)
        
        logger.info("âœ… å“è³ªã‚²ãƒ¼ãƒˆè² è·ãƒ†ã‚¹ãƒˆå®Œäº†")
        return {"quality_gates": quality_metrics}
    
    async def test_preview_interactive_load(self) -> Dict[str, Any]:
        """ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è² è·ãƒ†ã‚¹ãƒˆ"""
        logger.info("--- ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è² è·ãƒ†ã‚¹ãƒˆé–‹å§‹ ---")
        
        preview_metrics = PerformanceMetrics([], 0, 0, 0.0, 0.0, 0.0)
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼APIãƒ†ã‚¹ãƒˆ
        async def test_preview_endpoints(session: aiohttp.ClientSession):
            test_session_id = str(uuid4())
            
            endpoints = [
                f"/manga/{test_session_id}/preview/1",
                f"/manga/{test_session_id}/preview/2",
                f"/manga/{test_session_id}/preview/3"
            ]
            
            for endpoint in endpoints:
                try:
                    request_start = time.time()
                    
                    async with session.get(
                        f"{BASE_API_URL}{endpoint}",
                        headers={"Authorization": f"Bearer {TEST_TOKEN}"},
                        timeout=aiohttp.ClientTimeout(total=20)
                    ) as response:
                        await response.text()
                        
                        request_time = time.time() - request_start
                        preview_metrics.response_times.append(request_time)
                        
                        if response.status < 400:
                            preview_metrics.success_count += 1
                        else:
                            preview_metrics.error_count += 1
                            
                except Exception as e:
                    preview_metrics.error_count += 1
                    logger.debug(f"Preview interactive test error: {e}")
        
        # ä¸¦è¡Œãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚¹ãƒˆ
        async with aiohttp.ClientSession() as session:
            preview_tasks = []
            for _ in range(CONCURRENT_USERS * 2):
                task = asyncio.create_task(test_preview_endpoints(session))
                preview_tasks.append(task)
            
            await asyncio.gather(*preview_tasks, return_exceptions=True)
        
        logger.info("âœ… ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è² è·ãƒ†ã‚¹ãƒˆå®Œäº†")
        return {"preview_interactive": preview_metrics}
    
    async def test_database_load(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è² è·ãƒ†ã‚¹ãƒˆï¼ˆé–“æ¥çš„ï¼‰"""
        logger.info("--- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è² è·ãƒ†ã‚¹ãƒˆé–‹å§‹ ---")
        
        db_metrics = PerformanceMetrics([], 0, 0, 0.0, 0.0, 0.0)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å¤šç”¨ã™ã‚‹APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆ
        async def database_intensive_requests(session: aiohttp.ClientSession):
            for _ in range(5):  # å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ5å›å®Ÿè¡Œ
                try:
                    request_start = time.time()
                    
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›¸ãè¾¼ã¿ï¼‰
                    create_data = {
                        "input_text": f"è² è·ãƒ†ã‚¹ãƒˆç”¨ãƒãƒ³ã‚¬ç”Ÿæˆ {uuid4()}",
                        "hitl_enabled": False,
                        "quality_level": "high"
                    }
                    
                    async with session.post(
                        f"{BASE_API_URL}/manga/generate",
                        json=create_data,
                        headers={"Authorization": f"Bearer {TEST_TOKEN}"},
                        timeout=aiohttp.ClientTimeout(total=30)
                    ) as response:
                        await response.text()
                        
                        request_time = time.time() - request_start
                        db_metrics.response_times.append(request_time)
                        
                        if response.status < 400:
                            db_metrics.success_count += 1
                        else:
                            db_metrics.error_count += 1
                            
                except Exception as e:
                    db_metrics.error_count += 1
                    logger.debug(f"Database load test error: {e}")
                
                await asyncio.sleep(1.0)  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”
        
        # ä¸¦è¡Œãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ
        async with aiohttp.ClientSession() as session:
            db_tasks = []
            for i in range(CONCURRENT_USERS):
                task = asyncio.create_task(database_intensive_requests(session))
                db_tasks.append(task)
            
            await asyncio.gather(*db_tasks, return_exceptions=True)
        
        logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è² è·ãƒ†ã‚¹ãƒˆå®Œäº†")
        return {"database_load": db_metrics}
    
    async def monitor_system_resources(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–"""
        while True:
            try:
                # CPUä½¿ç”¨ç‡
                cpu_percent = psutil.cpu_percent(interval=1)
                
                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
                memory = psutil.virtual_memory()
                memory_percent = memory.percent
                
                # ãƒ‡ã‚£ã‚¹ã‚¯I/O
                disk_io = psutil.disk_io_counters()
                
                metric = {
                    "timestamp": datetime.utcnow(),
                    "cpu_percent": cpu_percent,
                    "memory_percent": memory_percent,
                    "memory_available_gb": memory.available / (1024**3),
                    "disk_read_mb_s": (disk_io.read_bytes if disk_io else 0) / (1024**2),
                    "disk_write_mb_s": (disk_io.write_bytes if disk_io else 0) / (1024**2)
                }
                
                self.system_metrics.append(metric)
                
                await asyncio.sleep(5)  # 5ç§’é–“éš”ã§ç›£è¦–
                
            except Exception as e:
                logger.debug(f"System monitoring error: {e}")
                await asyncio.sleep(5)
    
    async def analyze_and_report_results(self):
        """çµæœåˆ†æã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        logger.info("=== è² è·ãƒ†ã‚¹ãƒˆçµæœåˆ†æ ===")
        
        total_duration = time.time() - self.start_time
        
        # ç·åˆçµ±è¨ˆ
        logger.info(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚é–“: {total_duration:.2f}ç§’")
        logger.info(f"åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {CONCURRENT_USERS}")
        
        # å„ãƒ†ã‚¹ãƒˆã®çµæœè¡¨ç¤º
        for test_name, test_result in self.results.items():
            logger.info(f"\n--- {test_name} çµæœ ---")
            
            if isinstance(test_result, dict):
                for category_name, metrics in test_result.items():
                    if isinstance(metrics, PerformanceMetrics):
                        logger.info(f"\n{category_name}:")
                        logger.info(f"  æˆåŠŸç‡: {metrics.success_rate:.1f}%")
                        logger.info(f"  å¹³å‡å¿œç­”æ™‚é–“: {metrics.avg_response_time*1000:.2f}ms")
                        if metrics.response_times:
                            logger.info(f"  P95å¿œç­”æ™‚é–“: {metrics.p95_response_time*1000:.2f}ms")
                            logger.info(f"  P99å¿œç­”æ™‚é–“: {metrics.p99_response_time*1000:.2f}ms")
                        logger.info(f"  ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {metrics.throughput:.2f} req/s")
                        logger.info(f"  æˆåŠŸæ•°: {metrics.success_count}")
                        logger.info(f"  ã‚¨ãƒ©ãƒ¼æ•°: {metrics.error_count}")
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹åˆ†æ
        if self.system_metrics:
            logger.info(f"\n--- ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³ ---")
            
            avg_cpu = statistics.mean([m["cpu_percent"] for m in self.system_metrics])
            max_cpu = max([m["cpu_percent"] for m in self.system_metrics])
            
            avg_memory = statistics.mean([m["memory_percent"] for m in self.system_metrics])
            max_memory = max([m["memory_percent"] for m in self.system_metrics])
            
            logger.info(f"  å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu:.1f}%")
            logger.info(f"  æœ€å¤§CPUä½¿ç”¨ç‡: {max_cpu:.1f}%")
            logger.info(f"  å¹³å‡ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {avg_memory:.1f}%")
            logger.info(f"  æœ€å¤§ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {max_memory:.1f}%")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ¤å®š
        self.evaluate_performance()
        
        # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        await self.generate_detailed_report()
    
    def evaluate_performance(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡"""
        logger.info(f"\n=== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ ===")
        
        # è©•ä¾¡åŸºæº–
        criteria = {
            "api_response_time": 1000,  # 1ç§’ä»¥å†…
            "websocket_connection_time": 2000,  # 2ç§’ä»¥å†…
            "success_rate": 95,  # 95%ä»¥ä¸Š
            "throughput_per_user": 1,  # 1 req/s/userä»¥ä¸Š
            "system_cpu": 80,  # 80%ä»¥ä¸‹
            "system_memory": 80  # 80%ä»¥ä¸‹
        }
        
        passed_criteria = 0
        total_criteria = len(criteria)
        
        for test_name, test_result in self.results.items():
            if isinstance(test_result, dict):
                for category_name, metrics in test_result.items():
                    if isinstance(metrics, PerformanceMetrics):
                        # æˆåŠŸç‡ãƒã‚§ãƒƒã‚¯
                        if metrics.success_rate >= criteria["success_rate"]:
                            passed_criteria += 1
                            logger.info(f"âœ… {category_name} æˆåŠŸç‡: {metrics.success_rate:.1f}% (åŸºæº–: {criteria['success_rate']}%)")
                        else:
                            logger.warning(f"âŒ {category_name} æˆåŠŸç‡: {metrics.success_rate:.1f}% (åŸºæº–: {criteria['success_rate']}%)")
                        
                        # å¿œç­”æ™‚é–“ãƒã‚§ãƒƒã‚¯
                        avg_ms = metrics.avg_response_time * 1000
                        if avg_ms <= criteria["api_response_time"]:
                            logger.info(f"âœ… {category_name} å¹³å‡å¿œç­”æ™‚é–“: {avg_ms:.2f}ms (åŸºæº–: {criteria['api_response_time']}ms)")
                        else:
                            logger.warning(f"âŒ {category_name} å¹³å‡å¿œç­”æ™‚é–“: {avg_ms:.2f}ms (åŸºæº–: {criteria['api_response_time']}ms)")
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯
        if self.system_metrics:
            avg_cpu = statistics.mean([m["cpu_percent"] for m in self.system_metrics])
            avg_memory = statistics.mean([m["memory_percent"] for m in self.system_metrics])
            
            if avg_cpu <= criteria["system_cpu"]:
                passed_criteria += 1
                logger.info(f"âœ… å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu:.1f}% (åŸºæº–: {criteria['system_cpu']}%)")
            else:
                logger.warning(f"âŒ å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu:.1f}% (åŸºæº–: {criteria['system_cpu']}%)")
            
            if avg_memory <= criteria["system_memory"]:
                passed_criteria += 1
                logger.info(f"âœ… å¹³å‡ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {avg_memory:.1f}% (åŸºæº–: {criteria['system_memory']}%)")
            else:
                logger.warning(f"âŒ å¹³å‡ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {avg_memory:.1f}% (åŸºæº–: {criteria['system_memory']}%)")
        
        # ç·åˆè©•ä¾¡
        performance_score = (passed_criteria / total_criteria) * 100
        logger.info(f"\nğŸ¯ ç·åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢: {performance_score:.1f}%")
        
        if performance_score >= 80:
            logger.info("ğŸ‰ å„ªç§€ - ã‚·ã‚¹ãƒ†ãƒ ã¯é«˜è² è·æ¡ä»¶ä¸‹ã§ã‚‚è‰¯å¥½ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        elif performance_score >= 60:
            logger.info("âœ… è‰¯å¥½ - ã‚·ã‚¹ãƒ†ãƒ ã¯è¨±å®¹å¯èƒ½ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™")
        elif performance_score >= 40:
            logger.warning("âš ï¸ æ”¹å–„å¿…è¦ - ã„ãã¤ã‹ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡ŒãŒã‚ã‚Šã¾ã™")
        else:
            logger.error("âŒ è¦å¯¾å¿œ - é‡å¤§ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡ŒãŒã‚ã‚Šã¾ã™")
    
    async def generate_detailed_report(self):
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_filename = f"load_test_report_{timestamp}.json"
        
        report_data = {
            "test_config": {
                "concurrent_users": CONCURRENT_USERS,
                "test_duration_seconds": TEST_DURATION_SECONDS,
                "ramp_up_time_seconds": RAMP_UP_TIME_SECONDS,
                "start_time": datetime.fromtimestamp(self.start_time).isoformat(),
                "end_time": datetime.now().isoformat()
            },
            "results": {},
            "system_metrics": self.system_metrics
        }
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
        for test_name, test_result in self.results.items():
            if isinstance(test_result, dict):
                report_data["results"][test_name] = {}
                for category_name, metrics in test_result.items():
                    if isinstance(metrics, PerformanceMetrics):
                        report_data["results"][test_name][category_name] = {
                            "success_count": metrics.success_count,
                            "error_count": metrics.error_count,
                            "success_rate": metrics.success_rate,
                            "avg_response_time_ms": metrics.avg_response_time * 1000,
                            "p95_response_time_ms": metrics.p95_response_time * 1000,
                            "p99_response_time_ms": metrics.p99_response_time * 1000,
                            "throughput": metrics.throughput
                        }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        try:
            with open(report_filename, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2, default=str)
            logger.info(f"âœ… è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›: {report_filename}")
        except Exception as e:
            logger.error(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("AIæ¼«ç”»ç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹ è² è·ãƒ†ã‚¹ãƒˆãƒ„ãƒ¼ãƒ«")
    logger.info("=" * 50)
    
    # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    gc.collect()
    
    # è² è·ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    load_tester = LoadTester()
    await load_tester.run_comprehensive_load_test()
    
    logger.info("=== è² è·ãƒ†ã‚¹ãƒˆå®Œäº† ===")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("è² è·ãƒ†ã‚¹ãƒˆãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"è² è·ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()